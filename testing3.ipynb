{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96253d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import tensorflow_io as tfio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "from skimage import exposure, io, img_as_ubyte\n",
    "from skimage.morphology import disk\n",
    "from skimage.filters import rank\n",
    "from skimage.restoration import denoise_bilateral\n",
    "\n",
    "import skimage.exposure\n",
    "\n",
    "import tf_clahe\n",
    "import os\n",
    "import cv2\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be26c5e5-d55a-4362-a79c-f8bddb7b7764",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Homomorphic filter class\n",
    "class HomomorphicFilter:\n",
    "    \"\"\"Homomorphic filter implemented with diferents filters and an option to an external filter.\n",
    "    \n",
    "    High-frequency filters implemented:\n",
    "        butterworth\n",
    "        gaussian\n",
    "    Attributes:\n",
    "        a, b: Floats used on emphasis filter:\n",
    "            H = a + b*H\n",
    "        \n",
    "        .\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, a = 0.5, b = 1.5):\n",
    "        self.a = float(a)\n",
    "        self.b = float(b)\n",
    "\n",
    "    # Filters\n",
    "    def __butterworth_filter(self, I_shape, filter_params):\n",
    "        P = I_shape[0]/2\n",
    "        Q = I_shape[1]/2\n",
    "        U, V = np.meshgrid(range(I_shape[0]), range(I_shape[1]), sparse=False, indexing='ij')\n",
    "        Duv = (((U-P)**2+(V-Q)**2)).astype(float)\n",
    "        H = 1/(1+(Duv/filter_params[0]**2)**filter_params[1])\n",
    "        return (1 - H)\n",
    "\n",
    "    def __gaussian_filter(self, I_shape, filter_params):\n",
    "        P = I_shape[0]/2\n",
    "        Q = I_shape[1]/2\n",
    "        H = np.zeros(I_shape)\n",
    "        U, V = np.meshgrid(range(I_shape[0]), range(I_shape[1]), sparse=False, indexing='ij')\n",
    "        Duv = (((U-P)**2+(V-Q)**2)).astype(float)\n",
    "        H = np.exp((-Duv/(2*(filter_params[0])**2)))\n",
    "        return (1 - H)\n",
    "\n",
    "    # Methods\n",
    "    def __apply_filter(self, I, H):\n",
    "        H = np.fft.fftshift(H)\n",
    "        I_filtered = (self.a + self.b*H)*I\n",
    "        return I_filtered\n",
    "\n",
    "    def filter(self, I, filter_params, filter='butterworth', H = None):\n",
    "        \"\"\"\n",
    "        Method to apply homormophic filter on an image\n",
    "        Attributes:\n",
    "            I: Single channel image\n",
    "            filter_params: Parameters to be used on filters:\n",
    "                butterworth:\n",
    "                    filter_params[0]: Cutoff frequency \n",
    "                    filter_params[1]: Order of filter\n",
    "                gaussian:\n",
    "                    filter_params[0]: Cutoff frequency\n",
    "            filter: Choose of the filter, options:\n",
    "                butterworth\n",
    "                gaussian\n",
    "                external\n",
    "            H: Used to pass external filter\n",
    "        \"\"\"\n",
    "\n",
    "        #  Validating image\n",
    "        if len(I.shape) != 2:\n",
    "            raise Exception('Improper image')\n",
    "\n",
    "        # Take the image to log domain and then to frequency domain \n",
    "        I_log = np.log1p(np.array(I, dtype=\"float\"))\n",
    "        I_fft = np.fft.fft2(I_log)\n",
    "\n",
    "        # Filters\n",
    "        if filter=='butterworth':\n",
    "            H = self.__butterworth_filter(I_shape = I_fft.shape, filter_params = filter_params)\n",
    "        elif filter=='gaussian':\n",
    "            H = self.__gaussian_filter(I_shape = I_fft.shape, filter_params = filter_params)\n",
    "        elif filter=='external':\n",
    "            print('external')\n",
    "            if len(H.shape) != 2:\n",
    "                raise Exception('Invalid external filter')\n",
    "        else:\n",
    "            raise Exception('Selected filter not implemented')\n",
    "        \n",
    "        # Apply filter on frequency domain then take the image back to spatial domain\n",
    "        I_fft_filt = self.__apply_filter(I = I_fft, H = H)\n",
    "        I_filt = np.fft.ifft2(I_fft_filt)\n",
    "        I = np.exp(np.real(I_filt))-1\n",
    "        return np.float32(I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7353f59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def depth_estimation(inputFile, outputFile):\n",
    "    # load image as grayscale\n",
    "    # print(inputFile)\n",
    "    img = cv2.imread(inputFile, cv2.IMREAD_ANYDEPTH)\n",
    "\n",
    "    # stretch to full dynamic range\n",
    "    stretch = skimage.exposure.rescale_intensity(img, in_range='image', out_range=(0,255)).astype(np.uint8)\n",
    "\n",
    "    # convert to 3 channels\n",
    "    stretch = cv2.merge([stretch,stretch,stretch])\n",
    "\n",
    "    cv2.imwrite(outputFile, stretch)\n",
    "    \n",
    "def contrast_depth_estimation(inputFile, outputFile):\n",
    "    # load image as grayscale\n",
    "    img = cv2.imread(inputFile, cv2.IMREAD_ANYDEPTH)\n",
    "    \n",
    "    # original = img.copy()\n",
    "    xp = [0, 64, 128, 192, 255]\n",
    "    fp = [0, 16, 128, 240, 255]\n",
    "    x = np.arange(256)\n",
    "    table = np.interp(x, xp, fp).astype('uint8')\n",
    "    img = cv2.LUT(img, table)\n",
    "    \n",
    "    \n",
    "    stretch = cv2.merge([img,img,img])\n",
    "    \n",
    "    cv2.imwrite(outputFile, stretch)\n",
    "\n",
    "\n",
    "def convert_contrast(inputFile, outputFile):\n",
    "\n",
    "    img = tf.io.read_file(inputFile)\n",
    "    img = tf.io.decode_png(img, channels=1)\n",
    "    # print(tf.rank(img))\n",
    "    img = tf.cast(img, tf.float32)\n",
    "\n",
    "    \n",
    "    img =  tf.image.adjust_contrast(img, 0.25)\n",
    "\n",
    "    tf.keras.utils.save_img(outputFile, img)\n",
    "\n",
    "def convert_file_clahe(inputFile, outputFile):\n",
    "    bgr = cv2.imread(inputFile)\n",
    "\n",
    "    lab = cv2.cvtColor(bgr, cv2.COLOR_BGR2LAB)\n",
    "\n",
    "    lab_planes = cv2.split(lab)\n",
    "\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0,tileGridSize=(8,9))\n",
    "    # img = clahe.apply(lab)\n",
    "    eq_channels = []\n",
    "    for ch in lab_planes:\n",
    "        eq_channels.append(clahe.apply(ch))\n",
    "\n",
    "    eq_image = cv2.merge(eq_channels)\n",
    "\n",
    "    bgr = cv2.cvtColor(eq_image, cv2.COLOR_LAB2BGR)\n",
    "    cv2.imwrite(outputFile, bgr)\n",
    "\n",
    "def convert_grayscale(inputFile, outputFile):\n",
    "    bgr = cv2.imread(inputFile)\n",
    "\n",
    "    lab = cv2.cvtColor(bgr, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    cv2.imwrite(outputFile, lab)\n",
    "    \n",
    "def convert_file_global_equal(inputFile, outputFile):\n",
    "    img = cv2.imread(inputFile)\n",
    "    # img = skimage.io.imread(fname=inputFile)\n",
    "    lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\n",
    "\n",
    "    lab_planes = cv2.split(img)\n",
    "    eq_channels = []\n",
    "    for ch in lab_planes:\n",
    "        eq_channels.append(exposure.equalize_hist(ch))\n",
    "    \n",
    "    eq_image = cv2.merge(eq_channels)\n",
    "    # bgr = cv2.cvtColor(eq_image, cv2.COLOR_LAB2BGR)\n",
    "    \n",
    "    io.imsave(fname=outputFile, arr=img_as_ubyte(eq_image))\n",
    "\n",
    "def convert_file_local_equal(inputFile, outputFile):\n",
    "    img = cv2.imread(inputFile)\n",
    "    # img = skimage.io.imread(fname=inputFile)\n",
    "    lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\n",
    "    \n",
    "    lab_planes = cv2.split(img)\n",
    "    eq_channels = []\n",
    "    selem = disk(30)\n",
    "    for ch in lab_planes:\n",
    "        eq_channels.append(rank.equalize(ch, selem=selem))\n",
    "    \n",
    "    eq_image = cv2.merge(eq_channels)\n",
    "    bgr = cv2.cvtColor(eq_image, cv2.COLOR_LAB2BGR)\n",
    "    \n",
    "    io.imsave(fname=outputFile, arr=img_as_ubyte(img))\n",
    "    \n",
    "def convert_denoise(inputFile, outputFile):\n",
    "    img = cv2.imread(inputFile)\n",
    "    \n",
    "    img = denoise_bilateral(img_as_ubyte(img), sigma_color=0.1, sigma_spatial=15, multichannel=True)\n",
    "    \n",
    "    io.imsave(fname=outputFile, arr=img_as_ubyte(img))\n",
    "\n",
    "def convert_custom_method(inputFile, outputFile):\n",
    "    img = tf.io.read_file(inputFile)\n",
    "    img = tf.io.decode_bmp(img, channels=3)\n",
    "    # print(tf.rank(img))\n",
    "    img = tf.cast(img, tf.float32)\n",
    "\n",
    "    img = tfio.experimental.color.rgb_to_bgr(img)\n",
    "    img = tf.image.adjust_contrast(img, 11.)\n",
    "    img = tf.image.adjust_hue(img, 11.)\n",
    "    img = tf.image.adjust_gamma(img)\n",
    "    img = tfa.image.median_filter2d(img)\n",
    "    \n",
    "    tf.keras.utils.save_img(outputFile, img)\n",
    "\n",
    "def convert_image_format(inputFile, ext, dest_ext):\n",
    "    \n",
    "    if inputFile.endswith(ext): \n",
    "        prefix = inputFile.split(ext)[0]\n",
    "        im = Image.open(inputFile)\n",
    "        # print(prefix + dest_ext)\n",
    "        im.save(prefix + dest_ext) \n",
    "\n",
    "\n",
    "kernel_size = (20, 20)\n",
    "def histo_equalize(img):\n",
    "    lab_planes = cv2.split(img)\n",
    "    eq_channels = []\n",
    "    for ch in lab_planes:\n",
    "        eq_channels.append(cv2.equalizeHist(ch))\n",
    "\n",
    "    img = cv2.merge(eq_channels)\n",
    "\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_LAB2BGR)\n",
    "    return img\n",
    "\n",
    "def opening_ops(img):\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, kernel_size)\n",
    "    img = cv2.morphologyEx(img, cv2.MORPH_OPEN, kernel)\n",
    "    return img\n",
    "\n",
    "def closing_ops(img):\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, kernel_size)\n",
    "    img = cv2.morphologyEx(img, cv2.MORPH_CLOSE, kernel)\n",
    "    return img\n",
    "\n",
    "def gabor_filter(img):\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    g_kernel = cv2.getGaborKernel(kernel_size, 8.0, np.pi/4, 10.0, 0.5, 0, ktype=cv2.CV_32F)\n",
    "    img = cv2.filter2D(img, cv2.CV_8UC3, g_kernel)\n",
    "    return img\n",
    "\n",
    "def convert_custom_method_v2(inputFile, outputFile):\n",
    "    img = cv2.imread(inputFile)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\n",
    "\n",
    "    img = opening_ops(img)\n",
    "    img = closing_ops(img)\n",
    "    img = histo_equalize(img)\n",
    "    img = gabor_filter(img)\n",
    "    \n",
    "    img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
    "    cv2.imwrite(outputFile, img)\n",
    "\n",
    "def convert_sobelx(inputFile, outputFile):\n",
    "    img = cv2.imread(inputFile)\n",
    "    # img = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\n",
    "    img = cv2.Sobel(img, cv2.CV_64F,1,0,ksize=5)\n",
    "    # img = cv2.cvtColor(img, cv2.COLOR_LAB2BGR)\n",
    "    cv2.imwrite(outputFile, img)\n",
    "    # return img\n",
    "    \n",
    "def resize_image(inputFile, outputFile):\n",
    "    # print(inputFile)\n",
    "    img = cv2.imread(inputFile)\n",
    "    \n",
    "    img = cv2.resize(img, (481, 271))\n",
    "    \n",
    "    cv2.imwrite(outputFile, img)\n",
    "    \n",
    "def convert_sobelxy(inputFile, outputFile):\n",
    "    img = cv2.imread(inputFile)\n",
    "    # img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    img = cv2.Sobel(img,cv2.CV_32F,1,1,ksize=3)\n",
    "    # img = cv2.Sobel(img,cv2.CV_32F,0,1,ksize=3)\n",
    "    cv2.imwrite(outputFile, img)\n",
    "    \n",
    "def convert_custom_v3(inputFile, outputFile):\n",
    "    img = cv2.imread(inputFile)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    # img = cv2.GaussianBlur(img,(3,3),0)\n",
    "    img = cv2.Sobel(img,cv2.CV_64F,1,0,ksize=3)\n",
    "    img = cv2.Sobel(img,cv2.CV_64F,0,1,ksize=3)\n",
    "    # img = cv2.cvtColor(img, cv2.COLOR_LAB2BGR)\n",
    "    cv2.imwrite(outputFile, img)\n",
    "    # return img\n",
    "\n",
    "\n",
    "def homo_filter(inputFile, outputFile):\n",
    "    # Main code\n",
    "    img = cv2.imread(inputFile)[:, :, 0]\n",
    "    homo_filter = HomomorphicFilter(a = 0.5, b = 1.5)\n",
    "    img_filtered = homo_filter.filter(I=img, filter_params=[3,3])\n",
    "    \n",
    "    cv2.imwrite(outputFile, img_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc92eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "## convert colour of images\n",
    "for mode in [\"test_data\",\"train_data\"]:\n",
    "    for class_name in [\"normal\", \"defect\"]:\n",
    "        Input_dir = f'mura_data/RGB/mura_clean/{mode}/{class_name}/'\n",
    "        Out_dir = f'mura_data/RGB/mura_homo_filter/{mode}/{class_name}/'\n",
    "        a = os.listdir(Input_dir)\n",
    "        index = 0\n",
    "        for i in a:\n",
    "            index += 1\n",
    "            if i != \".DS_Store\" and i != \".ipynb_checkpoints\":\n",
    "\n",
    "                inputFile = Input_dir+i\n",
    "                OutputFile = Out_dir+i\n",
    "\n",
    "                # print(inputFile)\n",
    "                # convert_file_bcet(inputFile, OutputFile)\n",
    "                # convert_file_clahe(inputFile, OutputFile)\n",
    "                # resize_image(inputFile, OutputFile)\n",
    "                # convert_sobelx(inputFile, OutputFile)\n",
    "                # convert_sobelxy(inputFile, OutputFile)\n",
    "                # depth_estimation(inputFile, OutputFile)\n",
    "                # contrast_depth_estimation(inputFile, OutputFile)\n",
    "                homo_filter(inputFile, OutputFile)\n",
    "                # convert_custom_method_v2(inputFile, OutputFile)\n",
    "                # convert_file_clahe_v2(inputFile, OutputFile)\n",
    "                # convert_image_format(inputFile, \".bmp\", \".png\")\n",
    "                # convert_custom_method(inputFile, OutputFile)\n",
    "                # convert_file_global_equal(inputFile, OutputFile)\n",
    "                # convert_file_local_equal(inputFile, OutputFile)\n",
    "                # convert_grayscale(inputFile, OutputFile)\n",
    "                # convert_contrast(inputFile, OutputFile)\n",
    "                # convert_denoise(inputFile, OutputFile)\n",
    "                # convert_custom_v3(inputFile, OutputFile)\n",
    "            if index % 1000 == 0:\n",
    "                print(\"file: \",index)\n",
    "        print(\"done.\", class_name, mode)\n",
    "    #     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487b0fd6-740b-47f7-b60f-91ec51c4df88",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ebd9671-fd97-4a38-878d-57aa2e10b38c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
