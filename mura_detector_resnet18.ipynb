{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ISLP7e8o6ZDK",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# importing Neccessary Library and constant variable\n",
    "\n",
    "# !pip install tf_clahe\n",
    "# !pip install -U scikit-learn\n",
    "# !pip install matplotlib\n",
    "# !pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import tensorflow_io as tfio\n",
    "import tf_clahe\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from packaging import version\n",
    "import os\n",
    "from packaging import version\n",
    "from datetime import datetime\n",
    "# Import writer class from csv module\n",
    "from csv import DictWriter\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc, precision_score, recall_score, f1_score\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "IMG_H = 128\n",
    "IMG_W = 128\n",
    "IMG_C = 3  ## Change this to 1 for grayscale.\n",
    "\n",
    "print(\"TensorFlow version: \", tf.__version__)\n",
    "assert version.parse(tf.__version__).release[0] >= 2, \\\n",
    "    \"This notebook requires TensorFlow 2.0 or above.\"\n",
    "\n",
    "# Weight initializers for the Generator network\n",
    "WEIGHT_INIT = tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.2)\n",
    "AUTOTUNE = tf.data.AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class for SSIM loss function\n",
    "class SSIMLoss(tf.keras.losses.Loss):\n",
    "    def __init__(self,\n",
    "         reduction=tf.keras.losses.Reduction.AUTO,\n",
    "         name='SSIMLoss'):\n",
    "        super().__init__(reduction=reduction, name=name)\n",
    "\n",
    "    def call(self, ori, recon):\n",
    "        recon = tf.convert_to_tensor(recon)\n",
    "        ori = tf.cast(ori, recon.dtype)\n",
    "\n",
    "        # Loss 3: SSIM Loss\n",
    "#         loss_ssim =  tf.reduce_mean(1 - tf.image.ssim(ori, recon, max_val=1.0)[0]) \n",
    "        loss_ssim = tf.reduce_mean(1 - tf.image.ssim(ori, recon, 2.0))\n",
    "        return loss_ssim\n",
    "    \n",
    "# class for Feature loss function\n",
    "class FeatureLoss(tf.keras.losses.Loss):\n",
    "    def __init__(self,\n",
    "             reduction=tf.keras.losses.Reduction.AUTO,\n",
    "             name='FeatureLoss'):\n",
    "        super().__init__(reduction=reduction, name=name)\n",
    "\n",
    "    \n",
    "    def call(self, real, fake):\n",
    "        fake = tf.convert_to_tensor(fake)\n",
    "        real = tf.cast(real, fake.dtype)\n",
    "        # Loss 4: FEATURE Loss\n",
    "        loss_feat = tf.reduce_mean(tf.pow((real-fake), 2))\n",
    "        return loss_feat\n",
    "    \n",
    "# class for Adversarial loss function\n",
    "class AdversarialLoss(tf.keras.losses.Loss):\n",
    "    def __init__(self,\n",
    "             reduction=tf.keras.losses.Reduction.AUTO,\n",
    "             name='AdversarialLoss'):\n",
    "        super().__init__(reduction=reduction, name=name)\n",
    "\n",
    "    \n",
    "    def call(self, logits_in, labels_in):\n",
    "        labels_in = tf.convert_to_tensor(labels_in)\n",
    "        logits_in = tf.cast(logits_in, labels_in.dtype)\n",
    "        # Loss 4: FEATURE Loss\n",
    "        return tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=logits_in, labels=labels_in))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delcare all loss function that we will use\n",
    "\n",
    "# for adversarial loss\n",
    "# cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=False)\n",
    "cross_entropy = AdversarialLoss()\n",
    "# L1 Loss\n",
    "mae = tf.keras.losses.MeanAbsoluteError()\n",
    "# L2 Loss\n",
    "mse = tf.keras.losses.MeanSquaredError() \n",
    "feat = FeatureLoss()\n",
    "\n",
    "# SSIM loss\n",
    "ssim = SSIMLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Function for Balance Contrast Enhancement Technique (BCET)\n",
    "    This technique provides solution to biased color (RGB) composition. \n",
    "    The contrast of the image can be stretched or compressed without changing the histogram pattern of the input image(x).\n",
    "    The solution is based on the parabolic function obtained from the input image.\n",
    "'''\n",
    "@tf.function\n",
    "def bcet(img):\n",
    "\n",
    "    \n",
    "    Lmin = tf.reduce_min(img) # MINIMUM OF INPUT IMAGE\n",
    "#     Lmin = np.min(img) # MINIMUM OF INPUT IMAGE\n",
    "#     print(\"Lmin\", Lmin)\n",
    "    Lmax = tf.reduce_max(img) # MAXIMUM OF INPUT IMAGE\n",
    "#     Lmax = np.max(img) # MAXIMUM OF INPUT IMAGE\n",
    "#     print(\"Lmax\", Lmax)\n",
    "    Lmean = tf.reduce_mean(img) #MEAN OF INPUT IMAGE\n",
    "#     Lmean = np.mean(img) #MEAN OF INPUT IMAGE\n",
    "#     print(\"Lmean\", Lmean)\n",
    "    LMssum = tf.reduce_mean(img * img) #MEAN SQUARE SUM OF INPUT IMAGE\n",
    "#     LMssum = np.mean(pow(img, 2)) #MEAN SQUARE SUM OF INPUT IMAGE\n",
    "#     print(\"LMssum\", LMssum)\n",
    "\n",
    "    Gmin = tf.constant(0, dtype=\"float32\") #MINIMUM OF OUTPUT IMAGE\n",
    "    Gmax = tf.constant(255, dtype=\"float32\") #MAXIMUM OF OUTPUT IMAGE\n",
    "    Gmean = tf.constant(110, dtype=\"float32\") #MEAN OF OUTPUT IMAGE\n",
    "    \n",
    "    subber = tf.constant(2, dtype=\"float32\")\n",
    "    \n",
    "    # find b\n",
    "    \n",
    "    bnum = ((Lmax**subber)*(Gmean-Gmin)) - (LMssum*(Gmax-Gmin)) + ((Lmin**subber) *(Gmax-Gmean))\n",
    "    bden = subber * ((Lmax*(Gmean-Gmin)) - (Lmean*(Gmax-Gmin)) + (Lmin*(Gmax-Gmean)))\n",
    "    \n",
    "    b = bnum/bden\n",
    "    \n",
    "    # find a\n",
    "    a1 = Gmax-Gmin\n",
    "    a2 = Lmax-Lmin\n",
    "    a3 = Lmax+Lmin-(subber*b)\n",
    "            \n",
    "    a = a1/(a2*a3)\n",
    "    \n",
    "    # find c\n",
    "    c = Gmin - (a*(Lmin-b)**subber)\n",
    "    \n",
    "    # Process raster\n",
    "    y = a*((img - b)**subber) + c #PARABOLIC FUNCTION\n",
    "\n",
    "    return y\n",
    "\n",
    "def bcet_processing(img,channels=3):\n",
    "    img = tf.cast(img, tf.float32)\n",
    "    layers = []\n",
    "    for i in range(channels):\n",
    "        layer = img[:,:,i]\n",
    "        layer = bcet(layer)\n",
    "        layers.append(layer)\n",
    "        \n",
    "    final_image = tf.stack(layers, axis=-1)\n",
    "\n",
    "    return final_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for  preprocessing data \n",
    "def prep_stage(x):\n",
    "    ### implement clahe to images\n",
    "    # x = tf_clahe.clahe(x)\n",
    "    \n",
    "    ### implement BCET to iamges\n",
    "    # x = bcet_processing(x)\n",
    "    \n",
    "    ### custom \n",
    "    x = tfio.experimental.color.rgb_to_bgr(x)\n",
    "    x = tf.image.adjust_contrast(x, 11.)\n",
    "    x = tf.image.adjust_hue(x, 11.)\n",
    "    x = tf.image.adjust_gamma(x)\n",
    "    x = tfa.image.median_filter2d(x)\n",
    "    # x = tf.cast(x * 255.0, tf.uint8)\n",
    "    ### implement Histogram normalization to iamges\n",
    "    # x = tfa.image.equalize(x)\n",
    "\n",
    "    ### crop or pad images\n",
    "    # x = tf.image.resize_with_crop_or_pad(x, IMG_H, IMG_W)\n",
    "    x = tf.image.resize(x, (IMG_H, IMG_W))\n",
    "    return x\n",
    "\n",
    "def augment_dataset_batch_train(dataset_batch):\n",
    "\n",
    "    flip_up_down = dataset_batch.map(lambda x: (tf.image.flip_up_down(x)), \n",
    "              num_parallel_calls=AUTOTUNE)\n",
    "    \n",
    "    flip_left_right = dataset_batch.map(lambda x: (tf.image.flip_left_right(x)), \n",
    "              num_parallel_calls=AUTOTUNE)\n",
    "    \n",
    "    dataset_batch = dataset_batch.concatenate(flip_up_down)\n",
    "    dataset_batch = dataset_batch.concatenate(flip_left_right)\n",
    "    \n",
    "    \n",
    "    return dataset_batch\n",
    "\n",
    "def augment_dataset_batch_test(dataset_batch):\n",
    "    AUTOTUNE = tf.data.AUTOTUNE\n",
    "    \n",
    "    \n",
    "#     dataset_batch = dataset_batch.map(lambda x, y: (tf.image.grayscale_to_rgb(x), y))\n",
    "    \n",
    "#     dataset_batch = dataset_batch.map(lambda x, y: (tf.image.per_image_standardization(x), y), \n",
    "#               num_parallel_calls=AUTOTUNE)\n",
    "    \n",
    "    \n",
    "    return dataset_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data_with_labels(filepath, class_names):\n",
    "    image_list = []\n",
    "    label_list = []\n",
    "    for class_n in class_names:  # do dogs and cats\n",
    "        path = os.path.join(filepath,class_n)  # create path to dogs and cats\n",
    "        class_num = class_names.index(class_n)  # get the classification  (0 or a 1). 0=dog 1=cat\n",
    "\n",
    "        for img in tqdm(os.listdir(path)):  \n",
    "            if \".DS_Store\" != img:\n",
    "                filpath = os.path.join(path,img)\n",
    "#                 print(filpath, class_num)\n",
    "                image_list.append(filpath)\n",
    "                label_list.append(class_num)\n",
    "#     print(image_list, label_list)\n",
    "    return image_list, label_list\n",
    "\n",
    "\n",
    "def load_image(image_path):\n",
    "    img = tf.io.read_file(image_path)\n",
    "    img = tf.io.decode_bmp(img, channels=IMG_C)\n",
    "    img = prep_stage(img)\n",
    "    img = tf.cast(img, tf.float32)\n",
    "#     rescailing image from 0,255 to -1,1\n",
    "    img = (img - 127.5) / 127.5\n",
    "    \n",
    "    return img\n",
    "\n",
    "def load_image_with_label(image_path, label):\n",
    "    class_names = [\"normal\", \"defect\"]\n",
    "#     print(image_path)\n",
    "    img = tf.io.read_file(image_path)\n",
    "    img = tf.io.decode_bmp(img, channels=IMG_C)\n",
    "    img = prep_stage(img)\n",
    "    img = tf.cast(img, tf.float32)\n",
    "    #     rescailing image from 0,255 to -1,1\n",
    "    img = (img - 127.5) / 127.5\n",
    "    \n",
    "    return img, label\n",
    "\n",
    "\n",
    "def tf_dataset(images_path, batch_size, labels=False, class_names=None):\n",
    "  \n",
    "    dataset = tf.data.Dataset.from_tensor_slices(images_path)\n",
    "    dataset = dataset.shuffle(buffer_size=10240)\n",
    "    dataset = dataset.map(load_image, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    \n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def tf_dataset_labels(images_path, batch_size, class_names=None):\n",
    "    \n",
    "    filenames, labels = read_data_with_labels(images_path, class_names)\n",
    "#     print(\"testing\")\n",
    "#     print(filenames, labels)\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((filenames, labels))\n",
    "    dataset = dataset.shuffle(buffer_size=10240)\n",
    "    dataset = dataset.map(load_image_with_label, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    \n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6nZU71ZylN0y"
   },
   "outputs": [],
   "source": [
    "# load image dataset for testing with labels\n",
    "def load_image_test(filename, class_names, size=(IMG_H,IMG_W)):\n",
    "\t# load image with the preferred size\n",
    "    pixels = tf_dataset_labels(images_path=filename, batch_size=1, class_names=class_names)\n",
    "    pixels = augment_dataset_batch_test(pixels)\n",
    "    \n",
    "    return pixels\n",
    "\n",
    "# load image dataset for trainnig without labels\n",
    "def load_image_train(filename, batch_size):\n",
    "\t# load image with the preferred size\n",
    "    \n",
    "    pixels = tf_dataset(filename, batch_size)\n",
    "    \n",
    "    pixels = augment_dataset_batch_train(pixels)\n",
    "\n",
    "    return pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cVbvGULAlN0y"
   },
   "outputs": [],
   "source": [
    "def plot_roc_curve(fpr, tpr, name_model):\n",
    "    plt.plot(fpr, tpr, color='orange', label='ROC')\n",
    "    plt.plot([0, 1], [0, 1], color='darkblue', linestyle='--')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "    plt.legend()\n",
    "    plt.savefig(name_model+'_roc_curve.png')\n",
    "    plt.show()\n",
    "    plt.clf()\n",
    "    \n",
    "\n",
    "\n",
    "''' calculate the auc value for lables and scores'''\n",
    "def roc(labels, scores, name_model):\n",
    "    \"\"\"Compute ROC curve and ROC area for each class\"\"\"\n",
    "    roc_auc = dict()\n",
    "    # True/False Positive Rates.\n",
    "    fpr, tpr, threshold = roc_curve(labels, scores)\n",
    "    print(\"threshold: \", threshold)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    # get a threshod that perform very well.\n",
    "    optimal_idx = np.argmax(tpr - fpr)\n",
    "    optimal_threshold = threshold[optimal_idx]\n",
    "    # draw plot for ROC-Curve\n",
    "    plot_roc_curve(fpr, tpr, name_model)\n",
    "    \n",
    "    return roc_auc, optimal_threshold\n",
    "\n",
    "def plot_loss_with_rlabel(loss_value, real_label, name_model, prefix):\n",
    "    # 'bo-' means blue color, round points, solid lines\n",
    "    colours = [\"blue\" if x == 1.0 else \"red\" for x in real_label]\n",
    "    plt.scatter(list(range(0, len(real_label))), loss_value, label='loss_value',c = colours)\n",
    "#     plt.rcParams[\"figure.figsize\"] = (50,3)\n",
    "    # Set a title of the current axes.\n",
    "    plt.title(prefix + \"_\" + name_model)\n",
    "    # show a legend on the plot\n",
    "    red_patch = mpatches.Patch(color='red', label='Normal Display')\n",
    "    blue_patch = mpatches.Patch(color='blue', label='Defect Display')\n",
    "    plt.legend(handles=[red_patch, blue_patch])\n",
    "    # Display a figure.\n",
    "    plt.savefig(name_model + \"_\" + prefix +'_rec_feat_rlabel.png')\n",
    "    plt.show()\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                        normalize=False,\n",
    "                        title='Confusion matrix',\n",
    "                        cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "            horizontalalignment=\"center\",\n",
    "            color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.savefig(title+'_cm.png')\n",
    "    plt.show()\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xFL24bEX65GT"
   },
   "outputs": [],
   "source": [
    "def bn_act(x, act=True):\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    if act == True:\n",
    "        # x = tf.keras.layers.Activation(\"relu\")(x)\n",
    "        x = tf.keras.layers.LeakyReLU(0.2)(x)\n",
    "    return x\n",
    "\n",
    "def conv_block(x, filters, kernel_size=(3, 3), padding=\"same\", strides=1):\n",
    "    conv = bn_act(x)\n",
    "    conv = tf.keras.layers.Conv2D(filters, kernel_size, padding=padding, strides=strides)(conv)\n",
    "    return conv\n",
    "\n",
    "def stem(x, filters, kernel_size=(3, 3), padding=\"same\", strides=1):\n",
    "    conv = tf.keras.layers.Conv2D(filters, kernel_size, padding=padding, strides=strides)(x)\n",
    "    conv = conv_block(conv, filters, kernel_size=kernel_size, padding=padding, strides=strides)\n",
    "    \n",
    "    shortcut = tf.keras.layers.Conv2D(filters, kernel_size=(1, 1), padding=padding, strides=strides)(x)\n",
    "    shortcut = bn_act(shortcut, act=False)\n",
    "    \n",
    "    output = tf.keras.layers.Add()([conv, shortcut])\n",
    "    return output\n",
    "\n",
    "def residual_block(x, filters, kernel_size=(3, 3), padding=\"same\", strides=1):\n",
    "    res = conv_block(x, filters, kernel_size=kernel_size, padding=padding, strides=strides)\n",
    "    res = conv_block(res, filters, kernel_size=kernel_size, padding=padding, strides=1)\n",
    "    \n",
    "    shortcut = tf.keras.layers.Conv2D(filters, kernel_size=(1, 1), padding=padding, strides=strides)(x)\n",
    "    shortcut = bn_act(shortcut, act=False)\n",
    "    \n",
    "    output = tf.keras.layers.Add()([shortcut, res])\n",
    "    return output\n",
    "\n",
    "def upsample_concat_block(x, xskip):\n",
    "    u = tf.keras.layers.UpSampling2D((2, 2))(x)\n",
    "    c = tf.keras.layers.Concatenate()([u, xskip])\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create generator model based on resnet50 and unet network\n",
    "def build_generator_resnet18_unet(input_shape):\n",
    "    f = [16, 32, 64, 128, 256]\n",
    "    \n",
    "    ## Encoder\n",
    "    e0 = input_shape\n",
    "    e1 = stem(e0, f[0])\n",
    "    e2 = residual_block(e1, f[1], strides=2)\n",
    "    e3 = residual_block(e2, f[2], strides=2)\n",
    "    e4 = residual_block(e3, f[3], strides=2)\n",
    "    e5 = residual_block(e4, f[4], strides=2)\n",
    "    \n",
    "    ## Bridge\n",
    "    b0 = conv_block(e5, f[4], strides=1)\n",
    "    b1 = conv_block(b0, f[4], strides=1)\n",
    "    \n",
    "    ## Decoder\n",
    "    u1 = upsample_concat_block(b1, e4)\n",
    "    d1 = residual_block(u1, f[4])\n",
    "    \n",
    "    u2 = upsample_concat_block(d1, e3)\n",
    "    d2 = residual_block(u2, f[3])\n",
    "    \n",
    "    u3 = upsample_concat_block(d2, e2)\n",
    "    d3 = residual_block(u3, f[2])\n",
    "    \n",
    "    u4 = upsample_concat_block(d3, e1)\n",
    "    d4 = residual_block(u4, f[1])\n",
    "    \n",
    "    outputs = tf.keras.layers.Conv2D(3, (1, 1), padding=\"same\", activation=\"tanh\")(d4)\n",
    "    model = tf.keras.models.Model(inputs, outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create discriminator model\n",
    "def build_discriminator(inputs):\n",
    "    f = [2**i for i in range(4)]\n",
    "    x = inputs\n",
    "    for i in range(0, 4):\n",
    "        x = tf.keras.layers.SeparableConvolution2D(f[i] * IMG_H ,kernel_size= (3, 3), strides=(2, 2), padding='same', kernel_initializer=WEIGHT_INIT)(x)\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "        x = tf.keras.layers.LeakyReLU(0.2)(x)\n",
    "        x = tf.keras.layers.Dropout(0.3)(x)\n",
    "\n",
    "    \n",
    "    feature = x\n",
    "    \n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "    output = tf.keras.layers.Dense(1, activation=\"tanh\")(x)\n",
    "#     output = tf.keras.layers.Dense(1, activation=\"tanh\")(x)\n",
    "#     output = tf.keras.layers.Dense(1)(x)\n",
    "    \n",
    "    \n",
    "    model = tf.keras.models.Model(inputs, outputs = [feature, output])\n",
    "    \n",
    "    return model\n",
    "    # return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Bm_XokrmFnlN"
   },
   "outputs": [],
   "source": [
    "class ResUnetGAN(tf.keras.models.Model):\n",
    "    def __init__(self, generator, discriminator):\n",
    "        super(ResUnetGAN, self).__init__()\n",
    "        self.generator = generator\n",
    "        self.discriminator = discriminator\n",
    "       \n",
    "        # Regularization Rate for each loss function\n",
    "        self.ADV_REG_RATE_LF = 1\n",
    "        self.REC_REG_RATE_LF = 50\n",
    "        self.SSIM_REG_RATE_LF = 10\n",
    "        self.FEAT_REG_RATE_LF = 1\n",
    "        self.field_names = ['epoch', 'gen_loss', 'disc_loss']\n",
    "        self.d_optimizer = tf.keras.optimizers.Adam(learning_rate=2e-6, beta_1=0.5, beta_2=0.999)\n",
    "        self.g_optimizer = tf.keras.optimizers.Adam(learning_rate=2e-6, beta_1=0.5, beta_2=0.999)\n",
    "    \n",
    "    \n",
    "    def compile(self, g_optimizer, d_optimizer, filepath, resume=False):\n",
    "        super(ResUnetGAN, self).compile()\n",
    "        self.g_optimizer = g_optimizer\n",
    "        self.d_optimizer = d_optimizer\n",
    "#         columns name (epoch, gen_loss, disc_loss)\n",
    "        \n",
    "        \n",
    "        logs = pd.DataFrame([], columns=self.field_names)\n",
    "\n",
    "        if not resume:\n",
    "            logs.to_csv(filepath, encoding='utf-8', index=False)\n",
    "        else:\n",
    "            fileExist = os.path.exists(filepath)\n",
    "            if not fileExist:\n",
    "                print(\"file not found. then we create new file\")\n",
    "                logs.to_csv(filepath, encoding='utf-8', index=False)\n",
    "            \n",
    "\n",
    "            \n",
    "# Notice the use of `tf.function`\n",
    "# This annotation causes the function to be \"compiled\".\n",
    "    @tf.function\n",
    "    def train_step(self, images):\n",
    "\n",
    "        with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "            # tf.print(\"Images: \", images)\n",
    "            reconstructed_images = self.generator(images, training=True)\n",
    "            feature_real, label_real = self.discriminator(images, training=True)\n",
    "            # print(generated_images.shape)\n",
    "            feature_fake, label_fake = self.discriminator(reconstructed_images, training=True)\n",
    "\n",
    "            # Loss 1: ADVERSARIAL loss\n",
    "            real_loss = cross_entropy(label_real, tf.ones_like(label_real))\n",
    "            fake_loss = cross_entropy(label_fake, tf.zeros_like(label_fake))\n",
    "            adv_loss = real_loss + fake_loss\n",
    "            \n",
    "#             gen_adv_loss = cross_entropy(fake_output, tf.ones_like(fake_output))\n",
    "            \n",
    "            # Loss 2: RECONSTRUCTION loss (L1)\n",
    "            loss_rec = tf.reduce_mean(mae(images, reconstructed_images))\n",
    "        \n",
    "            # Loss 3: SSIM Loss\n",
    "            loss_ssim =  ssim(images, reconstructed_images)\n",
    "        \n",
    "            # Loss 4: FEATURE Loss\n",
    "#             loss_feat = tf.reduce_mean(mse(real_output, fake_output))\n",
    "            loss_feat = feat(feature_real, feature_fake)\n",
    "\n",
    "            gen_loss = tf.reduce_mean( (adv_loss * self.ADV_REG_RATE_LF) + (loss_rec * self.REC_REG_RATE_LF) + (loss_ssim * self.SSIM_REG_RATE_LF) + (loss_feat * self.FEAT_REG_RATE_LF) )\n",
    "            disc_loss = tf.reduce_mean( (adv_loss * self.ADV_REG_RATE_LF) + (loss_feat * self.FEAT_REG_RATE_LF) )\n",
    "#             disc_loss = adv_loss\n",
    "\n",
    "        gradients_of_discriminator = disc_tape.gradient(disc_loss, self.discriminator.trainable_variables)\n",
    "        gradients_of_generator = gen_tape.gradient(gen_loss, self.generator.trainable_variables)\n",
    "        \n",
    "\n",
    "        \n",
    "        self.d_optimizer.apply_gradients(zip(gradients_of_discriminator, self.discriminator.trainable_variables))\n",
    "        self.g_optimizer.apply_gradients(zip(gradients_of_generator, self.generator.trainable_variables))\n",
    "        \n",
    "\n",
    "\n",
    "        return {\n",
    "            \"gen_loss\": gen_loss,\n",
    "            \"disc_loss\": disc_loss,\n",
    "            \"adv_loss\": adv_loss,\n",
    "#             \"gen_adv_loss\": gen_adv_loss,\n",
    "            \"loss_rec\": loss_rec,\n",
    "            \"loss_ssim\": loss_ssim,\n",
    "            \"loss_feat\": loss_feat\n",
    "        }\n",
    "\n",
    "    def saved_model(self, gmodelpath, dmodelpath):\n",
    "        self.generator.save(gmodelpath)\n",
    "        self.discriminator.save(dmodelpath)\n",
    "\n",
    "    def loaded_model(self, g_filepath, d_filepath):\n",
    "        self.generator.load_weights(g_filepath)\n",
    "        self.discriminator.load_weights(d_filepath)\n",
    "        \n",
    "    # load and save data of training process\n",
    "    def load_save_processing(self,filepath, epoch_num, disc_loss, gen_loss, g_filepath, d_filepath, resume=False):\n",
    "        # columns name (epoch, gen_loss, disc_loss)\n",
    "\n",
    "        if resume:\n",
    "            # load logs data\n",
    "            logs = pd.read_csv(filepath)\n",
    "            logs.sort_values(\"epoch\", ascending=False)\n",
    "            epoch = max(logs['epoch'].tolist(), default=0)\n",
    "            \n",
    "            epoch_list = logs['epoch'].tolist()\n",
    "            disc_loss = logs['disc_loss'].tolist()\n",
    "            gen_loss = logs['gen_loss'].tolist()\n",
    "            \n",
    "            \n",
    "            # load model data\n",
    "            self.loaded_model(g_filepath, d_filepath)\n",
    "            print(epoch, disc_loss, gen_loss)\n",
    "            return epoch, epoch_list, disc_loss, gen_loss\n",
    "        \n",
    "        else:\n",
    "            data={'epoch':epoch_num,'disc_loss':disc_loss,'gen_loss':gen_loss}\n",
    "            print(\"row added.\" , data)\n",
    "            f_object = open(filepath, \"a+\")\n",
    "            dwriter = DictWriter(f_object, fieldnames=self.field_names)\n",
    "            dwriter.writerow(data)\n",
    "            f_object.close()\n",
    "            return None, None, None, None\n",
    "            \n",
    "            \n",
    "    def testing(self, filepath, g_filepath, d_filepath, name_model):\n",
    "#         threshold = 0.7\n",
    "        class_names = [\"normal\", \"defect\"] # normal = 0, defect = 1\n",
    "        test_dateset = load_image_test(filepath, class_names)\n",
    "        # print(test_dateset)\n",
    "        \n",
    "        # range between 0-1\n",
    "        anomaly_weight = 0.8\n",
    "        \n",
    "        scores_ano = []\n",
    "        real_label = []\n",
    "        rec_loss_list = []\n",
    "        feat_loss_list = []\n",
    "        i = 0\n",
    "        self.generator.load_weights(g_filepath)\n",
    "        self.discriminator.load_weights(d_filepath)\n",
    "        \n",
    "        \n",
    "        for images, labels in test_dateset:\n",
    "            i += 1\n",
    "            \n",
    "            reconstructed_images = self.generator(images, training=False)\n",
    "            feature_real, label_real  = self.discriminator(images, training=False)\n",
    "            # print(generated_images.shape)\n",
    "            feature_fake, label_fake = self.discriminator(reconstructed_images, training=False)\n",
    "\n",
    "            \n",
    "            # Loss 2: RECONSTRUCTION loss (L1)\n",
    "            loss_rec = tf.reduce_mean(mae(images, reconstructed_images))\n",
    "        \n",
    "        \n",
    "#         loss_feat = tf.reduce_mean( tf.keras.losses.mse(real, fake) )\n",
    "            loss_feat = feat(feature_real, feature_fake)\n",
    "\n",
    "            \n",
    "            score = (anomaly_weight * loss_rec) + ((1-anomaly_weight) * loss_feat)\n",
    "#             print(score, loss_rec, loss_feat)\n",
    "#             print(i, score.numpy(),labels.numpy()[0] )\n",
    "#          \n",
    "            scores_ano = np.append(scores_ano, score.numpy())\n",
    "            real_label = np.append(real_label, labels.numpy()[0])\n",
    "        \n",
    "            rec_loss_list = np.append(rec_loss_list, loss_rec)\n",
    "            feat_loss_list = np.append(feat_loss_list, loss_feat)\n",
    "        \n",
    "#             print(\"reconstruction loss: \", loss_rec.numpy(), \"feature losss: \", loss_feat.numpy(), \"label: \", labels.numpy(), \"score: \", score.numpy())\n",
    "        \n",
    "        \n",
    "        ''' Scale scores vector between [0, 1]'''\n",
    "        scores_ano = (scores_ano - scores_ano.min())/(scores_ano.max()-scores_ano.min())\n",
    "        plot_loss_with_rlabel(scores_ano, real_label, name_model, \"anomaly_score\")\n",
    "#         print(\"scores_ano: \", scores_ano)\n",
    "#         print(\"real_label: \", real_label)\n",
    "#         scores_ano = (scores_ano > threshold).astype(int)\n",
    "        auc_out, threshold = roc(real_label, scores_ano, name_model)\n",
    "        print(\"auc: \", auc_out)\n",
    "        print(\"threshold: \", threshold)\n",
    "        \n",
    "        \n",
    "        \n",
    "        scores_ano = (scores_ano > threshold).astype(int)\n",
    "        cm = tf.math.confusion_matrix(labels=real_label, predictions=scores_ano).numpy()\n",
    "        TP = cm[1][1]\n",
    "        FP = cm[0][1]\n",
    "        FN = cm[1][0]\n",
    "        TN = cm[0][0]\n",
    "        plot_confusion_matrix(cm, class_names, title=name_model)\n",
    "\n",
    "        plot_loss_with_rlabel(rec_loss_list, real_label, name_model, \"recontruction_loss\")\n",
    "        \n",
    "        diagonal_sum = cm.trace()\n",
    "        sum_of_all_elements = cm.sum()\n",
    "\n",
    "        print(\"Accuracy: \", diagonal_sum / sum_of_all_elements )\n",
    "        print(\"False Alarm Rate: \", FP/(FP+TP))\n",
    "        print(\"Leakage Rate: \", FN/(FN+TN))\n",
    "        print(\"precision_score: \",precision_score(real_label, scores_ano))\n",
    "#         print(\"recall_score: \", recall_score(real_label, scores_ano))\n",
    "        print(\"recall_score: \", TP/(TP+FN))\n",
    "#         F1 = 2 * (precision * recall) / (precision + recall)\n",
    "        print(\"F1-Score: \", f1_score(real_label, scores_ano))\n",
    "    \n",
    "    \n",
    "        \n",
    "    def checking_gen_disc(self, mode, g_filepath, d_filepath, test_data_path):\n",
    "        self.generator.load_weights(g_filepath)\n",
    "        self.discriminator.load_weights(d_filepath)\n",
    "#         path = \"mura_data/RGB/test_data/normal/normal.bmp\"\n",
    "#         path = \"mura_data/RGB/test_data/defect/defect.bmp\"\n",
    "#         path = \"rgb_serius_defect/BUTTERFLY (2).bmp\"\n",
    "        paths = {\n",
    "            \"normal\": test_data_path+\"/normal/normal.bmp\",\n",
    "            \"defect\": test_data_path+\"/defect/defect.bmp\",\n",
    "            \"butterfly_defect\": test_data_path+\"/defect/BUTTERFLY (2).bmp\",\n",
    "            \"water_defect\": test_data_path+\"/defect/0428-12 P20.bmp\"\n",
    "        }\n",
    "   \n",
    "        for i, v in paths.items():\n",
    "            print(i,v)\n",
    "            \n",
    "            width=IMG_W\n",
    "            height=IMG_H\n",
    "            rows = 1\n",
    "            cols = 3\n",
    "            axes=[]\n",
    "            fig = plt.figure()\n",
    "            \n",
    "            \n",
    "            img = tf.io.read_file(v)\n",
    "            img = tf.io.decode_bmp(img, channels=IMG_C)\n",
    "            \n",
    "            name_subplot = mode+'_original_'+i\n",
    "            axes.append( fig.add_subplot(rows, cols, 1) )\n",
    "            axes[-1].set_title('_original_')  \n",
    "            plt.imshow(img.numpy().astype(\"int64\"), alpha=1.0)\n",
    "            plt.axis('off')\n",
    "#             plt.savefig(name_original+'.png')\n",
    "        \n",
    "        \n",
    "        \n",
    "            img = prep_stage(img)\n",
    "            img = tf.cast(img, tf.float64)\n",
    "\n",
    "            name_subplot = mode+'_preprocessing_'+i\n",
    "            axes.append( fig.add_subplot(rows, cols, 2) )\n",
    "            axes[-1].set_title('_preprocessing_')  \n",
    "            plt.imshow(img.numpy().astype(\"int64\"), alpha=1.0)\n",
    "            plt.axis('off')\n",
    "            img = (img - 127.5) / 127.5\n",
    "#             plt.savefig(mode+'_preprocessing_'+i+'.png')\n",
    "   \n",
    "        \n",
    "            image = tf.reshape(img, (-1, IMG_H, IMG_W, IMG_C))\n",
    "            reconstructed_images = self.generator.predict(image)\n",
    "            reconstructed_images = tf.reshape(reconstructed_images, (IMG_H, IMG_W, IMG_C))\n",
    "#             reconstructed_images = reconstructed_images[0, :, :, 0] * 127.5 + 127.5\n",
    "#             reconstructed_images = reconstructed_images[0]\n",
    "            reconstructed_images = reconstructed_images * 127 + 127\n",
    "\n",
    "            name_subplot = mode+'_reconstructed_'+i\n",
    "            axes.append( fig.add_subplot(rows, cols, 3) )\n",
    "            axes[-1].set_title('_reconstructed_') \n",
    "            plt.imshow(reconstructed_images.numpy().astype(\"int64\"), alpha=1.0)\n",
    "            plt.axis('off')\n",
    "            \n",
    "            fig.tight_layout()    \n",
    "            fig.savefig(mode+'_'+i+'.png')\n",
    "            plt.show()\n",
    "            plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSaver(tf.keras.callbacks.Callback):\n",
    "    def __init__(self,\n",
    "                 g_model_path,\n",
    "                 d_model_path,\n",
    "                 logs_file,\n",
    "                 name_model\n",
    "                ):\n",
    "        super(CustomSaver, self).__init__()\n",
    "        self.g_model_path = g_model_path\n",
    "        self.d_model_path = d_model_path\n",
    "        self.logs_file = logs_file\n",
    "        self.name_model = name_model\n",
    "        self.epochs_list = []\n",
    "        self.gen_loss_list = []\n",
    "        self.disc_loss_list = []\n",
    "        \n",
    "    \n",
    "    def on_train_begin(self, logs=None):\n",
    "        if not hasattr(self, 'epoch'):\n",
    "            self.epoch = []\n",
    "            self.history = {}\n",
    "            \n",
    "    def on_train_end(self, logs=None):\n",
    "        self.model.saved_model(self.g_model_path, self.d_model_path)\n",
    "        \n",
    "        self.plot_epoch_result(self.epochs_list, self.gen_loss_list, \"Generator_Loss\", self.name_model, \"g\")\n",
    "        self.plot_epoch_result(self.epochs_list, self.disc_loss_list, \"Discriminator_Loss\", self.name_model, \"r\")\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        logs = logs or {}\n",
    "        self.epoch.append(epoch)\n",
    "        for k, v in logs.items():\n",
    "#             print(k, v)\n",
    "            self.history.setdefault(k, []).append(v)\n",
    "        \n",
    "        self.epochs_list.append(epoch)\n",
    "        self.gen_loss_list.append(logs[\"gen_loss\"])\n",
    "        self.disc_loss_list.append(logs[\"disc_loss\"])\n",
    "        \n",
    "        \n",
    "        self.model.load_save_processing(logs_file, epoch, logs[\"disc_loss\"], logs[\"gen_loss\"], self.g_model_path, self.d_model_path, resume=False) \n",
    "        \n",
    "        if (epoch + 1) % 15 == 0 or (epoch + 1) <= 15:\n",
    "            self.model.saved_model(self.g_model_path, self.d_model_path)\n",
    "            print('saved for epoch',epoch + 1)\n",
    "            \n",
    "    def plot_epoch_result(self, epochs, loss, name, model_name, colour):\n",
    "        plt.plot(epochs, loss, colour, label=name)\n",
    "    #     plt.plot(epochs, disc_loss, 'b', label='Discriminator loss')\n",
    "        plt.title(name)\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        plt.savefig(model_name+ '_'+name+'_epoch_result.png')\n",
    "        plt.show()\n",
    "        plt.clf()\n",
    "\n",
    "        \n",
    "def scheduler(epoch, lr):\n",
    "    if epoch < 1500:\n",
    "        return lr\n",
    "    else:\n",
    "        return lr * tf.math.exp(-0.1)\n",
    "\n",
    "def set_callbacks(name_model, logs_path, logs_file, path_gmodal, path_dmodal, steps):\n",
    "    # create and use callback:\n",
    "    \n",
    "    saver_callback = CustomSaver(\n",
    "        path_gmodal,\n",
    "        path_dmodal,\n",
    "        logs_file,\n",
    "        name_model\n",
    "    )\n",
    "    \n",
    "    lr_callback = tf.keras.callbacks.LearningRateScheduler(scheduler)\n",
    "    \n",
    "    reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='disc_loss', factor=0.2,\n",
    "                              patience=7, min_lr=0.000001)\n",
    "    \n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
    "        log_dir=logs_path + name_model + \"/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\"), \n",
    "        histogram_freq=1\n",
    "    )\n",
    "    \n",
    "\n",
    "    callbacks = [\n",
    "        saver_callback,\n",
    "#         checkpoints_callback,\n",
    "        tensorboard_callback,\n",
    "#         lr_callback,\n",
    "        reduce_lr,\n",
    "    ]\n",
    "    return callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_trainning(model, train_dataset,num_epochs, path_gmodal, path_dmodal, logs_path, logs_file, name_model, steps, resume=False):\n",
    "    init_epoch = 0\n",
    "    \n",
    "    \n",
    "    callbacks = set_callbacks(name_model, logs_path, logs_file, path_gmodal, path_dmodal, steps)\n",
    "    if resume:\n",
    "        print(\"resuming trainning. \", name_model)\n",
    "        skip_epoch, _, _, _ = model.load_save_processing(logs_file, num_epochs, [], [], path_gmodal, path_dmodal, resume=resume)\n",
    "        if skip_epoch < num_epochs:\n",
    "            init_epoch = skip_epoch\n",
    "            \n",
    "    model.fit(train_dataset, epochs=num_epochs, callbacks=callbacks, initial_epoch=init_epoch)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1KoSI9-4-tVt"
   },
   "outputs": [],
   "source": [
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    '''\n",
    "    In Default:\n",
    "    Clahe: OFF\n",
    "    BCET: OFF\n",
    "    Resize: crop or padding (decided by tensorflow)\n",
    "    Datasets: For trainning dataset, it'll have additional datasets (flip-up-down and flip-right-left)\n",
    "    '''\n",
    "    \n",
    "    # run the function here\n",
    "    \"\"\" Set Hyperparameters \"\"\"\n",
    "    \n",
    "    mode = \"custom\"\n",
    "    batch_size = 32\n",
    "    num_epochs = 1000\n",
    "    name_model= str(IMG_H)+\"_rgb_\"+mode+\"_\"+str(num_epochs)\n",
    "    \n",
    "    resume_trainning = False\n",
    "    lr = 1e-5\n",
    "    \n",
    "    print(\"start: \", name_model)\n",
    "    \n",
    "    # set dir of files\n",
    "    train_images_path = \"mura_data/RGB/train_data/normal/*.bmp\"\n",
    "    test_data_path = \"mura_data/RGB/clahe_test_data\"\n",
    "    saved_model_path = \"mura_data/RGB/saved_model/\"\n",
    "    \n",
    "    logs_path = \"mura_data/RGB/logs/\"\n",
    "    \n",
    "    logs_file = logs_path + \"logs_\" + name_model + \".csv\"\n",
    "    \n",
    "    path_gmodal = saved_model_path + name_model + \"_g_model\" + \".h5\"\n",
    "    path_dmodal = saved_model_path +  name_model + \"_d_model\" + \".h5\"\n",
    "    \n",
    "    \"\"\"\n",
    "    Create a MirroredStrategy object. \n",
    "    This will handle distribution and provide a context manager (MirroredStrategy.scope) \n",
    "    to build your model inside.\n",
    "    \"\"\"\n",
    "    \n",
    "    strategy = tf.distribute.MirroredStrategy()\n",
    "    \n",
    "    print('Number of devices: {}'.format(strategy.num_replicas_in_sync))\n",
    "\n",
    "    input_shape = (IMG_H, IMG_W, IMG_C)\n",
    "    # print(input_shape)\n",
    "    \n",
    "    ## init models ##\n",
    "    \n",
    "    # set input \n",
    "    inputs = tf.keras.layers.Input(input_shape, name=\"input_1\")\n",
    "    \n",
    "    g_model = build_generator_resnet18_unet(inputs)\n",
    "    \n",
    "    d_model = build_discriminator(inputs)\n",
    "    \n",
    "#     d_model.summary()\n",
    "#     g_model.summary()\n",
    "    \n",
    "    resunetgan = ResUnetGAN(g_model, d_model)\n",
    "    \n",
    "    g_optimizer = tf.keras.optimizers.Adam(learning_rate=lr, beta_1=0.5, beta_2=0.999)\n",
    "    d_optimizer = tf.keras.optimizers.Adam(learning_rate=lr, beta_1=0.5, beta_2=0.999)\n",
    "    \n",
    "    resunetgan.compile(g_optimizer, d_optimizer, logs_file, resume_trainning)\n",
    "    \n",
    "#     print(train_images_dataset)\n",
    "    \"\"\" run trainning process \"\"\"\n",
    "    train_images = glob(train_images_path)\n",
    "    train_images_dataset = load_image_train(train_images, batch_size)\n",
    "    train_images_dataset = train_images_dataset.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "    size_of_dataset = len(list(train_images_dataset)) * batch_size\n",
    "    \n",
    "    steps = int(size_of_dataset/batch_size)\n",
    "    run_trainning(resunetgan, train_images_dataset, num_epochs, path_gmodal, path_dmodal, logs_path, logs_file, name_model, steps,resume=resume_trainning)\n",
    "    \n",
    "#     \"\"\" run testing \"\"\"\n",
    "#     resunetgan.testing(test_data_path, path_gmodal, path_dmodal, name_model)\n",
    "    resunetgan.checking_gen_disc(mode, path_gmodal, path_dmodal, test_data_path)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "mura_detector.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
