{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b2f697-3c7a-4917-9d10-d905154d63e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import random\n",
    "import math\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import time\n",
    "from random import sample \n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.decomposition import PCA\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import recall_score,accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255926ed-7427-465a-bc17-4ae28a344d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "sob_normal_train_img_fn = glob('mura_data/RGB/mura_march_clean/train_data/normal/*.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8456456d-6bd5-46dd-b80e-6742b1fbc763",
   "metadata": {},
   "outputs": [],
   "source": [
    "ORI_SIZE = (271, 481)\n",
    "def sliding_crop_and_select_one(img, stepSize=32, windowSize=(256, 256)):\n",
    "    current_std = 0\n",
    "    current_image = None\n",
    "    y_end_crop, x_end_crop = False, False\n",
    "    for y in range(0, ORI_SIZE[0], stepSize):\n",
    "        \n",
    "        y_end_crop = False\n",
    "        \n",
    "        for x in range(0, ORI_SIZE[1], stepSize):\n",
    "            \n",
    "            x_end_crop = False\n",
    "            \n",
    "            crop_y = y\n",
    "            if (y + windowSize[0]) > ORI_SIZE[0]:\n",
    "                crop_y =  ORI_SIZE[0] - windowSize[0]\n",
    "                y_end_crop = True\n",
    "            \n",
    "            crop_x = x\n",
    "            if (x + windowSize[1]) > ORI_SIZE[1]:\n",
    "                crop_x = ORI_SIZE[1] - windowSize[1]\n",
    "                x_end_crop = True\n",
    "                \n",
    "            image = tf.image.crop_to_bounding_box(img, crop_y, crop_x, windowSize[0], windowSize[1])                \n",
    "            std_image = tf.math.reduce_std(tf.cast(image, dtype=tf.float32))\n",
    "          \n",
    "            if current_std == 0 or std_image < current_std :\n",
    "                current_std = std_image\n",
    "                current_image = image\n",
    "                \n",
    "            if x_end_crop:\n",
    "                break\n",
    "                \n",
    "        if x_end_crop and y_end_crop:\n",
    "            break\n",
    "            \n",
    "    return current_image\n",
    "\n",
    "\n",
    "def sliding_window(image, stepSize=20, windowSize=(256, 256)):\n",
    "    current_std = 0\n",
    "    current_image = None\n",
    "    # print(image.shape)\n",
    "    y_end_crop, x_end_crop = False, False\n",
    "    \n",
    "    for y in range(0, image.shape[0], stepSize):\n",
    "        y_end_crop = False\n",
    "        \n",
    "        for x in range(0, image.shape[1], stepSize):\n",
    "            \n",
    "            x_end_crop = False\n",
    "            \n",
    "            crop_y = y\n",
    "            if (y + windowSize[0]) > ORI_SIZE[0]:\n",
    "                crop_y =  ORI_SIZE[0] - windowSize[0]\n",
    "                y_end_crop = True\n",
    "            \n",
    "            crop_x = x\n",
    "            if (x + windowSize[1]) > ORI_SIZE[1]:\n",
    "                crop_x = ORI_SIZE[1] - windowSize[1]\n",
    "                x_end_crop = True\n",
    "            \n",
    "            # print(x, y)\n",
    "            img = image[crop_y:y + windowSize[0], crop_x:x + windowSize[1]]\n",
    "            std_image = np.std(img)\n",
    "            # print(std_image)\n",
    "            if current_std == 0 or std_image < current_std :\n",
    "                current_std = std_image\n",
    "                current_image = img\n",
    "            \n",
    "            if x_end_crop:\n",
    "                break\n",
    "                \n",
    "        if x_end_crop and y_end_crop:\n",
    "            break\n",
    "            \n",
    "    return current_image   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc809ed-e3c3-40f6-8243-9ed068a58c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputFile = \"mura_data/RGB/mura_clean/test_data/defect/defect1.png\"\n",
    "\n",
    "defect_img = cv2.imread(inputFile)\n",
    "img = sliding_window(defect_img)\n",
    "\n",
    "print(img.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e59689-0689-45d2-b6dc-354760489d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "N,w=10000,128\n",
    "\n",
    "def open_image(fn):\n",
    "    img = cv2.imread(fn)\n",
    "    \n",
    "    img = sliding_window(img)\n",
    "    # print(img)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    img = cv2.resize(img, dsize=(w, w), interpolation=cv2.INTER_CUBIC)\n",
    "    return img\n",
    "    \n",
    "read_img = lambda fn: np.array(open_image(fn)).ravel()\n",
    "load_imgs = lambda fn_list: np.array([read_img(fn) for fn in fn_list]).astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0de9749-af19-4fa4-86ba-547e4da7d6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sob_normal_train_imgs = load_imgs(sample(sob_normal_train_img_fn,N))\n",
    "\n",
    "print(sob_normal_train_imgs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30a3d91-3517-4e0a-a546-5b1ebc365c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=256)\n",
    "sob_normal_train_PCA = pca.fit(sob_normal_train_imgs)\n",
    "print(sob_normal_train_PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9650fdcd-932e-4be3-a294-53b6ce33ba76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PCA_IMG(inputFile, outputFile, inner_pca):\n",
    "    img = np.array(open_image(inputFile)).ravel().astype(\"float32\")\n",
    "    x_pca = inner_pca.transform([img])\n",
    "    x_inv = inner_pca.inverse_transform(x_pca)\n",
    "\n",
    "    img = np.reshape(x_inv[0], (-1, w))\n",
    "\n",
    "    # print(img.shape)\n",
    "    cv2.imwrite(OutputFile, img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64c7d4c-5faa-4f58-a5e4-8383dc5f2c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "## convert colour of images\n",
    "for mode in [\"test_data\",\"train_data\"]:\n",
    "    for class_name in [\"normal\", \"defect\"]:\n",
    "        Input_dir = f'mura_data/RGB/mura_march_clean/{mode}/{class_name}/'\n",
    "        Out_dir = f'mura_data/RGB/mura_pca_clean/{mode}/{class_name}/'\n",
    "        a = os.listdir(Input_dir)\n",
    "        index = 0\n",
    "        for i in a:\n",
    "            index += 1\n",
    "            if i != \".DS_Store\" and i != \".ipynb_checkpoints\":\n",
    "\n",
    "                inputFile = Input_dir+i\n",
    "                OutputFile = Out_dir+i\n",
    "                PCA_IMG(inputFile, OutputFile, pca)\n",
    "                \n",
    "                # if index == 1:\n",
    "                #     break\n",
    "            if index % 1000 == 0:\n",
    "                print(\"file: \",index)\n",
    "        print(\"done.\", class_name, mode)\n",
    "        # if index == 1:\n",
    "        #     break\n",
    "    #     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5280bacf-2718-4c18-95e8-0cd3bc96579c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
