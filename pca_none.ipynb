{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b2f697-3c7a-4917-9d10-d905154d63e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import random\n",
    "import math\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "from random import sample \n",
    "from sklearn.decomposition import PCA\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255926ed-7427-465a-bc17-4ae28a344d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_train_img_fn = glob('mura_data/RGB/mura_march_clean/train_data/normal/*.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8456456d-6bd5-46dd-b80e-6742b1fbc763",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_window(image, stepSize=20, windowSize=(256, 256)):\n",
    "    current_std = 0\n",
    "    current_image = None\n",
    "    # print(image.shape)\n",
    "    y_end_crop, x_end_crop = False, False\n",
    "    \n",
    "    for y in range(0, image.shape[0], stepSize):\n",
    "        y_end_crop = False\n",
    "        \n",
    "        for x in range(0, image.shape[1], stepSize):\n",
    "            \n",
    "            x_end_crop = False\n",
    "            \n",
    "            crop_y = y\n",
    "            if (y + windowSize[0]) > image.shape[0]:\n",
    "                crop_y =  image.shape[0] - windowSize[0]\n",
    "                y_end_crop = True\n",
    "            \n",
    "            crop_x = x\n",
    "            if (x + windowSize[1]) > image.shape[1]:\n",
    "                crop_x = image.shape[1] - windowSize[1]\n",
    "                x_end_crop = True\n",
    "            \n",
    "            # print(x, y)\n",
    "            img = image[crop_y:y + windowSize[0], crop_x:x + windowSize[1]]\n",
    "            std_image = np.std(img)\n",
    "            # print(std_image)\n",
    "            if current_std == 0 or std_image < current_std :\n",
    "                current_std = std_image\n",
    "                current_image = img\n",
    "            \n",
    "            if x_end_crop:\n",
    "                break\n",
    "                \n",
    "        if x_end_crop and y_end_crop:\n",
    "            break\n",
    "            \n",
    "    return current_image   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e59689-0689-45d2-b6dc-354760489d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "N,w=10000,256\n",
    "\n",
    "def open_image(fn):\n",
    "    img = cv2.imread(fn)\n",
    "    # print(img.shape)\n",
    "    # img = sliding_window(img)\n",
    "    # print(img)\n",
    "    # img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    img = cv2.resize(img, dsize=(w, w), interpolation=cv2.INTER_CUBIC)\n",
    "    b, g, r = cv2.split(img)\n",
    "    \n",
    "    flat_b = np.array(b).ravel()\n",
    "    flat_g = np.array(g).ravel()\n",
    "    flat_r = np.array(r).ravel()\n",
    "    return flat_b, flat_g, flat_r\n",
    "\n",
    "def load_imgs(img_list):\n",
    "    b_array = []\n",
    "    g_array = []\n",
    "    r_array = []\n",
    "    \n",
    "    for fn in img_list:\n",
    "        flat_b, flat_g, flat_r = open_image(fn)\n",
    "        b_array.append( np.array(flat_b).astype(\"float32\") )\n",
    "        g_array.append( np.array(flat_g).astype(\"float32\") )\n",
    "        r_array.append( np.array(flat_r).astype(\"float32\") )\n",
    "        \n",
    "    \n",
    "    return np.array(b_array), np.array(g_array), np.array(r_array)\n",
    "    \n",
    "    \n",
    "# read_img = lambda fn: np.array(open_image(fn)).ravel()\n",
    "# load_imgs = lambda fn_list: np.array([read_img(fn) for fn in fn_list]).astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0de9749-af19-4fa4-86ba-547e4da7d6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "b_normal_train_imgs, g_normal_train_imgs, r_normal_train_imgs = load_imgs(sample(normal_train_img_fn,N))\n",
    "\n",
    "print(b_normal_train_imgs.shape)\n",
    "print(g_normal_train_imgs.shape)\n",
    "print(r_normal_train_imgs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30a3d91-3517-4e0a-a546-5b1ebc365c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_b = PCA(n_components=256)\n",
    "pca_g = PCA(n_components=256)\n",
    "pca_r = PCA(n_components=256)\n",
    "\n",
    "b_normal_train_PCA = pca_b.fit(b_normal_train_imgs)\n",
    "g_normal_train_PCA = pca_g.fit(g_normal_train_imgs)\n",
    "r_normal_train_PCA = pca_r.fit(r_normal_train_imgs)\n",
    "\n",
    "print(b_normal_train_PCA)\n",
    "print(g_normal_train_PCA)\n",
    "print(r_normal_train_PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9650fdcd-932e-4be3-a294-53b6ce33ba76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PCA_IMG(inputFile, outputFile, b_inner_pca, g_inner_pca, r_inner_pca):\n",
    "    b, g, r = open_image(inputFile)\n",
    "    # r_scaled = r / 255\n",
    "    r_scaled = [r] \n",
    "    \n",
    "    # g_scaled = g / 255\n",
    "    g_scaled = [g] \n",
    "    \n",
    "    # b_scaled = b / 255\n",
    "    b_scaled = [b] \n",
    "    \n",
    "\n",
    "    pca_r_trans = r_inner_pca.transform(r_scaled)\n",
    "\n",
    "    pca_g_trans = g_inner_pca.transform(g_scaled)\n",
    "\n",
    "    pca_b_trans = b_inner_pca.transform(b_scaled)\n",
    "\n",
    "    pca_r_org = r_inner_pca.inverse_transform(pca_r_trans)\n",
    "    pca_r_final = np.reshape(pca_r_org[0], (-1, w))\n",
    "    \n",
    "    # print(pca_r_final.shape)\n",
    "    \n",
    "    pca_g_org = g_inner_pca.inverse_transform(pca_g_trans)\n",
    "    pca_g_final = np.reshape(pca_g_org[0], (-1, w))\n",
    "    # print(pca_g_final.shape)\n",
    "    \n",
    "    pca_b_org = b_inner_pca.inverse_transform(pca_b_trans)\n",
    "    pca_b_final = np.reshape(pca_b_org[0], (-1, w))\n",
    "    # print(pca_b_final.shape)\n",
    "    \n",
    "    \n",
    "    img_compressed = cv2.merge((pca_b_final, pca_g_final, pca_r_final))\n",
    "    # print(img_compressed.shape)\n",
    "    # print(img_compressed)\n",
    "    # img = img_compressed * 255\n",
    "    img = img_compressed\n",
    "    cv2.imwrite(outputFile, img)\n",
    "    # cv2.imwrite(\"test.png\", img)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64c7d4c-5faa-4f58-a5e4-8383dc5f2c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "## convert colour of images\n",
    "for mode in [\"test_data\",\"train_data\"]:\n",
    "    for class_name in [\"normal\", \"defect\"]:\n",
    "        Input_dir = f'mura_data/RGB/mura_march_clean/{mode}/{class_name}/'\n",
    "        Out_dir = f'mura_data/RGB/mura_pca_clean/{mode}/{class_name}/'\n",
    "        a = os.listdir(Input_dir)\n",
    "        index = 0\n",
    "        for i in a:\n",
    "            index += 1\n",
    "            if i != \".DS_Store\" and i != \".ipynb_checkpoints\":\n",
    "\n",
    "                inputFile = Input_dir+i\n",
    "                OutputFile = Out_dir+i\n",
    "                PCA_IMG(inputFile, OutputFile, b_normal_train_PCA, g_normal_train_PCA, r_normal_train_PCA)\n",
    "                \n",
    "                # if index == 1:\n",
    "                #     break\n",
    "            if index % 1000 == 0:\n",
    "                print(\"file: \",index)\n",
    "        print(\"done.\", class_name, mode)\n",
    "        # if index == 1:\n",
    "        #     break\n",
    "    #     break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
