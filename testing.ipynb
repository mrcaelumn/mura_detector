{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1892974a-dfea-48f1-96f8-f9f2c1560af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import skimage.exposure\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e7d30b-f1ec-4da7-9a7d-22cebd49cda8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ORI_SIZE = (271, 481)\n",
    "def sliding_crop(inputFile, stepSize=64, windowSize=(256, 256)):\n",
    "    splited_images = []\n",
    "    img = tf.io.read_file(inputFile)\n",
    "    img = tf.io.decode_png(img, channels=3)\n",
    "    y_end_crop, x_end_crop = False, False\n",
    "    for y in range(0, ORI_SIZE[0], stepSize):\n",
    "        y_end_crop = False\n",
    "        for x in range(0, ORI_SIZE[1], stepSize):\n",
    "            x_end_crop = False\n",
    "           \n",
    "            if (y + windowSize[0]) > ORI_SIZE[0]:\n",
    "                y = ORI_SIZE[0] - windowSize[0]\n",
    "                y_end_crop = True\n",
    "            \n",
    "        \n",
    "            if (x + windowSize[1]) > ORI_SIZE[1]:\n",
    "                x = ORI_SIZE[1] - windowSize[1]\n",
    "                x_end_crop = True\n",
    "                \n",
    "                \n",
    "            if x_end_crop:\n",
    "                break\n",
    "            print(y, x)\n",
    "            splited_images.append(tf.image.crop_to_bounding_box(img, y, x, windowSize[0], windowSize[1]))    \n",
    "            \n",
    "        if x_end_crop and y_end_crop:\n",
    "            break\n",
    "                \n",
    "    \n",
    "    return splited_images\n",
    "\n",
    "def calculate_std_select_image(images):\n",
    "    current_std = 0\n",
    "    current_image = []\n",
    "    list_std = []\n",
    "    for ix in images:\n",
    "        std_image = tf.math.reduce_std(tf.cast(ix, dtype=tf.float32))\n",
    "        print(current_std)\n",
    "        if std_image > current_std or current_std == 0:\n",
    "            current_std = std_image\n",
    "            current_image = ix\n",
    "        list_std.append(std_image)\n",
    "    print(current_std)\n",
    "    print(current_image)\n",
    "    return current_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ed7c6f-4cc4-445d-bc2f-9b6168794bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_left_and_right(inputFile, IMG_W=256, IMG_H=256):\n",
    "    img = cv2.imread(inputFile)\n",
    "    h = img.shape[0]\n",
    "    w = img.shape[1]\n",
    "    \n",
    "    img_left = img[0:0+IMG_H, 0:0+IMG_W]\n",
    "    img_right = img[h-IMG_H:h, w-IMG_W:w]\n",
    "    \n",
    "    return img_left, img_right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96104aa4-b5ef-452c-a24a-f0a2cb8784ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_left_and_right_tf(inputFile):\n",
    "    ORI_SIZE = (271, 481)\n",
    "    IMG_H = 271\n",
    "    IMG_W = 256\n",
    "    img = tf.io.read_file(inputFile)\n",
    "    img = tf.io.decode_bmp(img, channels=3)\n",
    "    # print(tf.rank(img))\n",
    "    img = tf.cast(img, tf.float32)\n",
    "\n",
    "    img_left = tf.image.crop_to_bounding_box(img, 0, 0, IMG_H, IMG_W)\n",
    "    img_right = tf.image.crop_to_bounding_box(img, ORI_SIZE[0] - IMG_H, ORI_SIZE[1] - IMG_W, IMG_H, IMG_W)\n",
    "    return img_left, img_right\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1e8137-b274-42e3-8bb9-520365f2be35",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputFile = \"mura_data/RGB/mura_clean/test_data/defect/defect.png\"\n",
    "\n",
    "defect_img = cv2.imread(inputFile)\n",
    "\n",
    "plt.imshow(defect_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014d3ab0-36a0-4ab8-9699-e8fffa513fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defect_img, grad_colored = contrast_depth_estimation(inputFile)\n",
    "# defect_img = homo_filter(inputFile)\n",
    "# defect_img_left, defect_img_right = crop_left_and_right_tf(inputFile)\n",
    "images = sliding_crop(inputFile)\n",
    "# defect_img = read_depth(inputFile)\n",
    "print(len(images))\n",
    "# std_images = calculate_std_select_image(images)\n",
    "\n",
    "# # plt.imshow(defect_img_left.numpy().astype(np.uint8))\n",
    "# fig, axes = plt.subplots(5,8, figsize=(32,32))\n",
    "\n",
    "# for i,ax in enumerate(axes.flat):\n",
    "#     ax.imshow(images[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ddec19a-1ccd-45a3-b8ec-2e1f70837c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(defect_img_right.numpy().astype(np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d1e7b0-1edd-4116-9b3f-c74c7d326358",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputFile = \"mura_data/RGB/mura_clean/test_data/normal/normal.png\"\n",
    "\n",
    "normal_img = cv2.imread(inputFile)\n",
    "# plt.imshow(normal_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a683ff07-d874-4096-905b-978d1b529f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = sliding_crop(inputFile)\n",
    "# defect_img = read_depth(inputFile)\n",
    "print(len(images))\n",
    "# plt.imshow(defect_img_left.numpy().astype(np.uint8))\n",
    "fig, axes = plt.subplots(5,8, figsize=(32,32))\n",
    "\n",
    "for i,ax in enumerate(axes.flat):\n",
    "    ax.imshow(images[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c10118a-2e83-4a0b-b44e-a0c0e22fb1a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
