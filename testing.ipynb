{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1892974a-dfea-48f1-96f8-f9f2c1560af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import skimage.exposure\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e7d30b-f1ec-4da7-9a7d-22cebd49cda8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ORI_SIZE = (271, 481)\n",
    "def sliding_crop(inputFile, stepSize=64, windowSize=(256, 256)):\n",
    "    splited_images = []\n",
    "    img = tf.io.read_file(inputFile)\n",
    "    img = tf.io.decode_png(img, channels=3)\n",
    "    y_end_crop, x_end_crop = False, False\n",
    "    for y in range(0, ORI_SIZE[0], stepSize):\n",
    "        y_end_crop = False\n",
    "        for x in range(0, ORI_SIZE[1], stepSize):\n",
    "            x_end_crop = False\n",
    "           \n",
    "            if (y + windowSize[0]) > ORI_SIZE[0]:\n",
    "                y = ORI_SIZE[0] - windowSize[0]\n",
    "                y_end_crop = True\n",
    "            \n",
    "        \n",
    "            if (x + windowSize[1]) > ORI_SIZE[1]:\n",
    "                x = ORI_SIZE[1] - windowSize[1]\n",
    "                x_end_crop = True\n",
    "                \n",
    "                \n",
    "            if x_end_crop:\n",
    "                break\n",
    "            print(y, x)\n",
    "            splited_images.append(tf.image.crop_to_bounding_box(img, y, x, windowSize[0], windowSize[1]))    \n",
    "            \n",
    "        if x_end_crop and y_end_crop:\n",
    "            break\n",
    "                \n",
    "    \n",
    "    return splited_images\n",
    "\n",
    "def calculate_std_select_image(images):\n",
    "    current_std = 0\n",
    "    current_image = []\n",
    "    list_std = []\n",
    "    for ix in images:\n",
    "        std_image = tf.math.reduce_std(tf.cast(ix, dtype=tf.float32))\n",
    "        print(current_std)\n",
    "        if std_image > current_std or current_std == 0:\n",
    "            current_std = std_image\n",
    "            current_image = ix\n",
    "        list_std.append(std_image)\n",
    "    print(current_std)\n",
    "    print(current_image)\n",
    "    return current_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ed7c6f-4cc4-445d-bc2f-9b6168794bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_left_and_right(inputFile, IMG_W=256, IMG_H=256):\n",
    "    img = cv2.imread(inputFile)\n",
    "    h = img.shape[0]\n",
    "    w = img.shape[1]\n",
    "    \n",
    "    img_left = img[0:0+IMG_H, 0:0+IMG_W]\n",
    "    img_right = img[h-IMG_H:h, w-IMG_W:w]\n",
    "    \n",
    "    return img_left, img_right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96104aa4-b5ef-452c-a24a-f0a2cb8784ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_left_and_right_tf(inputFile):\n",
    "    ORI_SIZE = (271, 481)\n",
    "    IMG_H = 271\n",
    "    IMG_W = 256\n",
    "    img = tf.io.read_file(inputFile)\n",
    "    img = tf.io.decode_bmp(img, channels=3)\n",
    "    # print(tf.rank(img))\n",
    "    img = tf.cast(img, tf.float32)\n",
    "\n",
    "    img_left = tf.image.crop_to_bounding_box(img, 0, 0, IMG_H, IMG_W)\n",
    "    img_right = tf.image.crop_to_bounding_box(img, ORI_SIZE[0] - IMG_H, ORI_SIZE[1] - IMG_W, IMG_H, IMG_W)\n",
    "    return img_left, img_right\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80747b3-239d-477a-9e0f-30cc14cdf75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Homomorphic filter class\n",
    "class HomomorphicFilter:\n",
    "    \"\"\"Homomorphic filter implemented with diferents filters and an option to an external filter.\n",
    "    \n",
    "    High-frequency filters implemented:\n",
    "        butterworth\n",
    "        gaussian\n",
    "    Attributes:\n",
    "        a, b: Floats used on emphasis filter:\n",
    "            H = a + b*H\n",
    "        \n",
    "        .\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, a = 0.5, b = 1.5):\n",
    "        self.a = float(a)\n",
    "        self.b = float(b)\n",
    "\n",
    "    # Filters\n",
    "    def __butterworth_filter(self, I_shape, filter_params):\n",
    "        P = I_shape[0]/2\n",
    "        Q = I_shape[1]/2\n",
    "        U, V = np.meshgrid(range(I_shape[0]), range(I_shape[1]), sparse=False, indexing='ij')\n",
    "        Duv = (((U-P)**2+(V-Q)**2)).astype(float)\n",
    "        H = 1/(1+(Duv/filter_params[0]**2)**filter_params[1])\n",
    "        return (1 - H)\n",
    "\n",
    "    def __gaussian_filter(self, I_shape, filter_params):\n",
    "        P = I_shape[0]/2\n",
    "        Q = I_shape[1]/2\n",
    "        H = np.zeros(I_shape)\n",
    "        U, V = np.meshgrid(range(I_shape[0]), range(I_shape[1]), sparse=False, indexing='ij')\n",
    "        Duv = (((U-P)**2+(V-Q)**2)).astype(float)\n",
    "        H = np.exp((-Duv/(2*(filter_params[0])**2)))\n",
    "        return (1 - H)\n",
    "\n",
    "    # Methods\n",
    "    def __apply_filter(self, I, H):\n",
    "        H = np.fft.fftshift(H)\n",
    "        I_filtered = (self.a + self.b*H)*I\n",
    "        return I_filtered\n",
    "\n",
    "    def filter(self, I, filter_params, filter='butterworth', H = None):\n",
    "        \"\"\"\n",
    "        Method to apply homormophic filter on an image\n",
    "        Attributes:\n",
    "            I: Single channel image\n",
    "            filter_params: Parameters to be used on filters:\n",
    "                butterworth:\n",
    "                    filter_params[0]: Cutoff frequency \n",
    "                    filter_params[1]: Order of filter\n",
    "                gaussian:\n",
    "                    filter_params[0]: Cutoff frequency\n",
    "            filter: Choose of the filter, options:\n",
    "                butterworth\n",
    "                gaussian\n",
    "                external\n",
    "            H: Used to pass external filter\n",
    "        \"\"\"\n",
    "\n",
    "        #  Validating image\n",
    "        if len(I.shape) != 2:\n",
    "            raise Exception('Improper image')\n",
    "\n",
    "        # Take the image to log domain and then to frequency domain \n",
    "        I_log = np.log1p(np.array(I, dtype=\"float\"))\n",
    "        I_fft = np.fft.fft2(I_log)\n",
    "\n",
    "        # Filters\n",
    "        if filter=='butterworth':\n",
    "            H = self.__butterworth_filter(I_shape = I_fft.shape, filter_params = filter_params)\n",
    "        elif filter=='gaussian':\n",
    "            H = self.__gaussian_filter(I_shape = I_fft.shape, filter_params = filter_params)\n",
    "        elif filter=='external':\n",
    "            print('external')\n",
    "            if len(H.shape) != 2:\n",
    "                raise Exception('Invalid external filter')\n",
    "        else:\n",
    "            raise Exception('Selected filter not implemented')\n",
    "        \n",
    "        # Apply filter on frequency domain then take the image back to spatial domain\n",
    "        I_fft_filt = self.__apply_filter(I = I_fft, H = H)\n",
    "        I_filt = np.fft.ifft2(I_fft_filt)\n",
    "        I = np.exp(np.real(I_filt))-1\n",
    "        return np.float32(I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e4997c-9036-48da-8adf-0cd9093bfccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LoG_Filter(inputFile):\n",
    "    img = cv2.imread(inputFile)\n",
    "    img = cv2.GaussianBlur(img, (3, 3), 0)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    img = cv2.Laplacian(img, cv2.CV_16S, ksize=3)\n",
    " \n",
    "    \n",
    "    f = np.fft.fft2(img)\n",
    "    fshift = np.fft.fftshift(f)\n",
    "    img = 30*np.log(np.abs(fshift))\n",
    "\n",
    "    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce61693-2b40-4204-a7a5-c585a392a1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def homo_filter(inputFile):\n",
    "    # Main code\n",
    "    img = cv2.imread(inputFile)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    homo_filter = HomomorphicFilter(a = 0.75, b = 1.75)\n",
    "    img_filtered = homo_filter.filter(I=img, filter_params=[3,3])\n",
    "\n",
    "    # f = np.fft.fft2(img)\n",
    "    # fshift = np.fft.fftshift(f)\n",
    "    # img = 30*np.log(np.abs(fshift))\n",
    "    \n",
    "    return img_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1e8137-b274-42e3-8bb9-520365f2be35",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputFile = \"mura_data/RGB/mura_clean/test_data/defect/defect.png\"\n",
    "\n",
    "defect_img = cv2.imread(inputFile)\n",
    "\n",
    "plt.imshow(defect_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014d3ab0-36a0-4ab8-9699-e8fffa513fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defect_img = LoG_Filter(inputFile)\n",
    "defect_img = homo_filter(inputFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ddec19a-1ccd-45a3-b8ec-2e1f70837c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(defect_img.astype(np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d1e7b0-1edd-4116-9b3f-c74c7d326358",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputFile = \"mura_data/RGB/mura_clean/test_data/normal/normal.png\"\n",
    "\n",
    "normal_img = cv2.imread(inputFile)\n",
    "plt.imshow(normal_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a683ff07-d874-4096-905b-978d1b529f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normal_img = LoG_Filter(inputFile)\n",
    "normal_img = homo_filter(inputFile)\n",
    "plt.imshow(normal_img.astype(np.uint8))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
