{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1892974a-dfea-48f1-96f8-f9f2c1560af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import skimage.exposure\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e7d30b-f1ec-4da7-9a7d-22cebd49cda8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ORI_SIZE = (271, 481)\n",
    "def sliding_crop(img, stepSize=64, windowSize=(256, 256)):\n",
    "    splited_images = []\n",
    "    # img = tf.io.read_file(inputFile)\n",
    "    # img = tf.io.decode_png(img, channels=3)\n",
    "    y_end_crop, x_end_crop = False, False\n",
    "    for y in range(0, ORI_SIZE[0], stepSize):\n",
    "        y_end_crop = False\n",
    "        for x in range(0, ORI_SIZE[1], stepSize):\n",
    "            x_end_crop = False\n",
    "           \n",
    "            if (y + windowSize[0]) > ORI_SIZE[0]:\n",
    "                y = ORI_SIZE[0] - windowSize[0]\n",
    "                y_end_crop = True\n",
    "            \n",
    "        \n",
    "            if (x + windowSize[1]) > ORI_SIZE[1]:\n",
    "                x = ORI_SIZE[1] - windowSize[1]\n",
    "                x_end_crop = True\n",
    "                \n",
    "                \n",
    "            if x_end_crop:\n",
    "                break\n",
    "            # print(y, x)\n",
    "            splited_images.append(tf.image.crop_to_bounding_box(img, y, x, windowSize[0], windowSize[1]))    \n",
    "            \n",
    "        if x_end_crop and y_end_crop:\n",
    "            break\n",
    "                \n",
    "    \n",
    "    return splited_images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c47644-f1ac-4a3b-a286-be0f2ee200b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PCA_img_compressed(img, n_comp=256):\n",
    "    # print(defect_img.shape)\n",
    "    b, g, r = cv2.split(defect_img)\n",
    "\n",
    "    # print(\"Red channel\")\n",
    "    # print(type(r))\n",
    "    # print(r.shape)\n",
    "    # print(\"\\nGreen channel\")\n",
    "    # print(type(g))\n",
    "    # print(g.shape)\n",
    "    # print(\"\\nBlue channel\")\n",
    "    # print(type(b))\n",
    "    # print(b.shape)\n",
    "\n",
    "    r_scaled = r / 255\n",
    "    g_scaled = g / 255\n",
    "    b_scaled = b / 255\n",
    "\n",
    "    pca_r = PCA(n_components=n_comp)\n",
    "    pca_r_trans = pca_r.fit_transform(r_scaled)\n",
    "\n",
    "    pca_g = PCA(n_components=n_comp)\n",
    "    pca_g_trans = pca_g.fit_transform(g_scaled)\n",
    "\n",
    "    pca_b = PCA(n_components=n_comp)\n",
    "    pca_b_trans = pca_b.fit_transform(b_scaled)\n",
    "\n",
    "    pca_r_org = pca_r.inverse_transform(pca_r_trans)\n",
    "    pca_g_org = pca_g.inverse_transform(pca_g_trans)\n",
    "    pca_b_org = pca_b.inverse_transform(pca_b_trans)\n",
    "\n",
    "    img_compressed = cv2.merge((pca_b_org, pca_g_org, pca_r_org))\n",
    "    img = img_compressed * 255\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1e8137-b274-42e3-8bb9-520365f2be35",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputFile = \"mura_data/RGB/mura_clean/test_data/defect/defect1.png\"\n",
    "\n",
    "defect_img = cv2.imread(inputFile)\n",
    "# print(defect_img.shape)\n",
    "defect_img = PCA_img_compressed(defect_img)\n",
    "# print(defect_img)\n",
    "print(len(images))\n",
    "plt.imshow(defect_img.astype(np.uint8))\n",
    "cv2.imwrite(\"testing1.png\", defect_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e322a284-8388-4635-8317-49de4a00b7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = sliding_crop(defect_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b58406-aac6-46fc-a387-506b4370503d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 7))\n",
    "# setting values to rows and column variables\n",
    "rows = 4\n",
    "columns = 4\n",
    "counter = 0\n",
    "# print(len(images))\n",
    "for image in images:\n",
    "    # print(counter)\n",
    "    counter += 1\n",
    "    # Adds a subplot at the 1st position\n",
    "    fig.add_subplot(rows, columns, counter)\n",
    "\n",
    "    # showing image\n",
    "    # print(image.shape)\n",
    "    plt.imshow(image)\n",
    "    plt.axis('off')\n",
    "    plt.title(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d1e7b0-1edd-4116-9b3f-c74c7d326358",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputFile = \"mura_data/RGB/mura_clean/test_data/normal/normal1.png\"\n",
    "\n",
    "normal_img = cv2.imread(inputFile)\n",
    "plt.imshow(normal_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a683ff07-d874-4096-905b-978d1b529f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normal_img = LoG_Filter(inputFile)\n",
    "normal_img = homo_filter(inputFile)\n",
    "plt.imshow(normal_img.astype(np.uint8))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
