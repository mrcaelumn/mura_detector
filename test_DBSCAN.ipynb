{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6769158-9293-4bea-91aa-93b774967c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import random\n",
    "import math\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plot\n",
    "from random import sample "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623b68e4-f56c-4d57-84d2-4cfe8e86c047",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad62fb5-ae7d-4cfd-99dc-7da99ce9f452",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_path = glob('mura_data/RGB/mura_march_clean/train_data/normal/*.png')\n",
    "\n",
    "limit = 1000\n",
    "\n",
    "print(len(images_path))\n",
    "\n",
    "if len(images_path) < limit or limit == 0:\n",
    "    print(\"The amount of dataset smaller than limit so we will use all images in dataset.\")\n",
    "else:\n",
    "    images_path = sample(images_path,limit)\n",
    "    \n",
    "# def dbscan_preprocessing(images_path, limit=None):\n",
    "    # images_path_array = glob(images_path)\n",
    "print(len(images_path))   \n",
    "df_analysis = pd.DataFrame(columns=['image_path','mean','std'])\n",
    "\n",
    "for img_path in images_path:\n",
    "    image = cv2.imread(img_path)\n",
    "    # print(image)\n",
    "    mean = np.mean(image)\n",
    "    std = np.std(image)\n",
    "    # print(mean, image.mean())\n",
    "    # print(std, image.std())\n",
    "    data_row = {\n",
    "        \"image_path\": img_path,\n",
    "        \"mean\": image.mean(),\n",
    "        \"std\": image.std(),\n",
    "        # \"class\": 0\n",
    "    }\n",
    "    df_analysis = df_analysis.append(data_row, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a813a470-726e-4657-8470-41da294bcd35",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = df_analysis.sort_values(['std', 'mean'], ascending = [True, False])\n",
    "# Draw a scatter plot\n",
    "final_df.plot.scatter(x = 'mean', y = 'std', s = 3, c=\"red\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8cc275-64c9-4bfa-922f-280c5c990afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.head(1000).plot.scatter(x = 'mean', y = 'std', s = 3, c=\"red\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c33b65-ffda-41d1-99ed-9786d03c495e",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_image_path = final_df['image_path'].head(100).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed732d72-6145-4b8d-bf83-fe702f7b5c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def selecting_images_preprocessing(images_path_array, limit_image_to_process=\"MAX\", limit_image_to_train = \"MAX\"):\n",
    "    # images_path_array = glob(images_path)\n",
    "    \n",
    "    original_number_number_image = len(images_path_array)\n",
    "    \n",
    "    print(\"original number of data: \", original_number_number_image)\n",
    "    \n",
    "    if limit_image_to_train == \"MAX\":\n",
    "        limit_image_to_train = original_number_number_image\n",
    "    \n",
    "    \n",
    "    if len(images_path) < limit_image_to_process:\n",
    "        print(\"The amount of dataset smaller than limit so we will use all images in dataset.\")\n",
    "    elif limit_image_to_process == \"MAX\":\n",
    "        print(\"You choose to use all of data. please wait it will take a moment.\")\n",
    "    else:\n",
    "        images_path_array = sample(images_path_array,limit_image_to_process)\n",
    "    print(\"processed number of data: \", len(images_path_array))\n",
    "    \n",
    "    df_analysis = pd.DataFrame(columns=['image_path','mean','std'])\n",
    "\n",
    "    for img_path in images_path_array:\n",
    "        image = cv2.imread(img_path)\n",
    "        # print(image)\n",
    "        mean = np.mean(image)\n",
    "        std = np.std(image)\n",
    "        # print(mean, image.mean())\n",
    "        # print(std, image.std())\n",
    "        data_row = {\n",
    "            \"image_path\": img_path,\n",
    "            \"mean\": image.mean(),\n",
    "            \"std\": image.std(),\n",
    "            # \"class\": 0\n",
    "        }\n",
    "        df_analysis = df_analysis.append(data_row, ignore_index = True)\n",
    "    final_df = df_analysis.sort_values(['std', 'mean'], ascending = [True, False])\n",
    "    \n",
    "    final_image_path = final_df['image_path'].head(limit_image_to_train).tolist()\n",
    "    return final_image_path"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
