{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9eb38b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_io as tfio\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import tf_clahe\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "\n",
    "IMG_H = 271\n",
    "IMG_W = 481\n",
    "IMG_C = 3  ## Change this to 1 for grayscale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b897d0-b644-47d6-8a53-1d844901b2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Function for Balance Contrast Enhancement Technique (BCET)\n",
    "    This technique provides solution to biased color (RGB) composition. \n",
    "    The contrast of the image can be stretched or compressed without changing the histogram pattern of the input image(x).\n",
    "    The solution is based on the parabolic function obtained from the input image.\n",
    "'''\n",
    "@tf.function\n",
    "def bcet(img):\n",
    "\n",
    "    \n",
    "    Lmin = tf.reduce_min(img) # MINIMUM OF INPUT IMAGE\n",
    "#     Lmin = np.min(img) # MINIMUM OF INPUT IMAGE\n",
    "#     print(\"Lmin\", Lmin)\n",
    "    Lmax = tf.reduce_max(img) # MAXIMUM OF INPUT IMAGE\n",
    "#     Lmax = np.max(img) # MAXIMUM OF INPUT IMAGE\n",
    "#     print(\"Lmax\", Lmax)\n",
    "    Lmean = tf.reduce_mean(img) #MEAN OF INPUT IMAGE\n",
    "#     Lmean = np.mean(img) #MEAN OF INPUT IMAGE\n",
    "#     print(\"Lmean\", Lmean)\n",
    "    LMssum = tf.reduce_mean(img * img) #MEAN SQUARE SUM OF INPUT IMAGE\n",
    "#     LMssum = np.mean(pow(img, 2)) #MEAN SQUARE SUM OF INPUT IMAGE\n",
    "#     print(\"LMssum\", LMssum)\n",
    "\n",
    "    Gmin = tf.constant(0, dtype=\"float32\") #MINIMUM OF OUTPUT IMAGE\n",
    "    Gmax = tf.constant(255, dtype=\"float32\") #MAXIMUM OF OUTPUT IMAGE\n",
    "    Gmean = tf.constant(110, dtype=\"float32\") #MEAN OF OUTPUT IMAGE\n",
    "    \n",
    "    subber = tf.constant(2, dtype=\"float32\")\n",
    "    \n",
    "    # find b\n",
    "    \n",
    "    bnum = ((Lmax**subber)*(Gmean-Gmin)) - (LMssum*(Gmax-Gmin)) + ((Lmin**subber) *(Gmax-Gmean))\n",
    "    bden = subber * ((Lmax*(Gmean-Gmin)) - (Lmean*(Gmax-Gmin)) + (Lmin*(Gmax-Gmean)))\n",
    "    \n",
    "    b = bnum/bden\n",
    "    \n",
    "    # find a\n",
    "    a1 = Gmax-Gmin\n",
    "    a2 = Lmax-Lmin\n",
    "    a3 = Lmax+Lmin-(subber*b)\n",
    "            \n",
    "    a = a1/(a2*a3)\n",
    "    \n",
    "    # find c\n",
    "    c = Gmin - (a*(Lmin-b)**subber)\n",
    "    \n",
    "    # Process raster\n",
    "    y = a*((img - b)**subber) + c #PARABOLIC FUNCTION\n",
    "\n",
    "    return y\n",
    "\n",
    "def bcet_processing(img,channels=3):\n",
    "    img = tf.cast(img, tf.float32)\n",
    "    layers = [None] * 3\n",
    "    for i in range(channels):\n",
    "        layer = img[:,:,i]\n",
    "        layer = bcet(layer)\n",
    "        layers[i] = layer\n",
    "       \n",
    "        \n",
    "    final_image = tf.stack(layers, axis=-1)\n",
    "\n",
    "    return final_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35fb9dea-418c-4928-baf2-0b61607f25c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "def prepare(x):\n",
    "    \n",
    "\n",
    "    ### implement BCET to iamges\n",
    "    # x = bcet_processing(x)\n",
    "    \n",
    "    ### implement clahe\n",
    "    # x = tf_clahe.clahe(x)\n",
    "    \n",
    "    ### Convert RGB to CIE XYZ\n",
    "    \n",
    "    # x = tfio.experimental.color.rgb_to_xyz(x)\n",
    "    # # # convert back uint8\n",
    "    \n",
    "    \n",
    "    # x = tfio.experimental.color.rgb_to_ycbcr(x)\n",
    "    # x = tf.cast(x, tf.float32) / 255.0\n",
    "    \n",
    "    # x = tfio.experimental.color.rgb_to_bgr(x)\n",
    "    x = tf.image.adjust_contrast(x, 9.)\n",
    "    x = tf.image.adjust_hue(x, 9.)\n",
    "    x = tf.image.adjust_gamma(x)\n",
    "    x = tfa.image.median_filter2d(x)\n",
    "    # x = tf.cast(x * 255.0, tf.uint8)\n",
    "    \n",
    "    # x = tfa.image.equalize(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99444d55-a2fd-457c-8180-8fa22575ada4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data_with_labels(filepath, class_names):\n",
    "    image_list = []\n",
    "    label_list = []\n",
    "    for class_n in class_names:  # do dogs and cats\n",
    "        path = os.path.join(filepath,class_n)  # create path to dogs and cats\n",
    "        class_num = class_names.index(class_n)  # get the classification  (0 or a 1). 0=dog 1=cat\n",
    "\n",
    "        for img in tqdm(os.listdir(path)):  \n",
    "            if \".DS_Store\" != img:\n",
    "                filpath = os.path.join(path,img)\n",
    "#                 print(filpath, class_num)\n",
    "                image_list.append(filpath)\n",
    "                label_list.append(class_num)\n",
    "#     print(image_list, label_list)\n",
    "    return image_list, label_list\n",
    "\n",
    "def load_image_with_label(image_path, label):\n",
    "    class_names = [\"normal\", \"defect\"]\n",
    "#     print(image_path)\n",
    "    img = tf.io.read_file(image_path)\n",
    "    img = tf.io.decode_bmp(img, channels=IMG_C)\n",
    "    img = prepare(img)\n",
    "    img = tf.cast(img, tf.float32)\n",
    "    #     rescailing image from 0,255 to -1,1\n",
    "    # img = (img - 127.5) / 127.5\n",
    "    \n",
    "    return img, label\n",
    "\n",
    "def tf_dataset_labels(images_path, batch_size, class_names=None):\n",
    "    \n",
    "    filenames, labels = read_data_with_labels(images_path, class_names)\n",
    "#     print(\"testing\")\n",
    "#     print(filenames, labels)\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((filenames, labels))\n",
    "    dataset = dataset.shuffle(buffer_size=10240)\n",
    "    dataset = dataset.map(load_image_with_label, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    \n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23be2ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_file = \"playground/\"\n",
    "class_names = [\"normal\", \"defect\", \"serius_defect\"]\n",
    "\n",
    "\n",
    "ds = tf_dataset_labels(path_file, 32, class_names)\n",
    "\n",
    "plt.figure(figsize=(13, 13))\n",
    "for images, labels in ds.take(1):\n",
    "    for i in range(12):\n",
    "        ax = plt.subplot(4, 4, i + 1)\n",
    "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "        plt.title(class_names[labels[i]])\n",
    "        plt.axis(\"off\")\n",
    "plt.savefig('viewer_custom.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
