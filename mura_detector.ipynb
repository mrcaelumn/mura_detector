{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "name": "mura_detector.ipynb",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "ISLP7e8o6ZDK"
   },
   "source": [
    "import PIL\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import time\n",
    "import os\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "IMG_H = 128\n",
    "IMG_W = 128\n",
    "IMG_C = 3  ## Change this to 1 for grayscale.\n",
    "\n",
    "\n",
    "# Regularization Rate for each loss function\n",
    "\n",
    "# This method returns a helper function to compute cross entropy loss\n",
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "\n",
    "# Loss function for evaluating adversarial loss\n",
    "adv_loss_fn = tf.losses.MeanSquaredError()\n",
    "\n",
    "w_init = tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.02)"
   ],
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "QjzYjrZEp3k9"
   },
   "source": [
    "def load_image(image_path):\n",
    "  img = tf.io.read_file(image_path)\n",
    "  img = tf.io.decode_bmp(img)\n",
    "  img = tf.image.resize_with_crop_or_pad(img, IMG_H, IMG_W)\n",
    "  img = tf.cast(img, tf.float32)\n",
    "  img = (img - 127.5) / 127.5\n",
    "  return img"
   ],
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "QT7glm2zsyYk"
   },
   "source": [
    "def tf_dataset(images_path, batch_size):\n",
    "  dataset = tf.data.Dataset.from_tensor_slices(images_path)\n",
    "  dataset = dataset.shuffle(buffer_size=10240)\n",
    "  dataset = dataset.map(load_image, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "  dataset = dataset.batch(batch_size)\n",
    "  dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "  return dataset"
   ],
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "xFL24bEX65GT"
   },
   "source": [
    "def conv_block(input, num_filters):\n",
    "    x = tf.keras.layers.Conv2D(num_filters, kernel_size=(1,1), padding=\"same\")(input)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Activation(\"relu\")(x)\n",
    "\n",
    "    x = tf.keras.layers.Conv2D(num_filters, kernel_size=(3,3), padding=\"same\")(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Activation(\"relu\")(x)\n",
    "\n",
    "    return x"
   ],
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "aPVAOjNg69AQ"
   },
   "source": [
    "def decoder_block(input, skip_features, num_filters):\n",
    "    x = tf.keras.layers.Conv2DTranspose(num_filters, (1, 1), strides=2, padding=\"same\")(input)\n",
    "    x = tf.keras.layers.Concatenate()([x, skip_features])\n",
    "    x = conv_block(x, num_filters)\n",
    "    return x"
   ],
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Bm_XokrmFnlN"
   },
   "source": [
    "class ResUnetGAN(tf.keras.models.Model):\n",
    "    def __init__(self, input_shape, batch_size):\n",
    "        super(ResUnetGAN, self).__init__()\n",
    "        self.discriminator = self.build_discriminator(input_shape)\n",
    "        self.generator = self.build_generator_resnet50_unet(input_shape)\n",
    "        self.batch_size = batch_size\n",
    "        self.ADV_REG_RATE_LF = 1\n",
    "        self.REC_REG_RATE_LF = 50\n",
    "        self.SSIM_REG_RATE_LF = 50\n",
    "        self.FEAT_REG_RATE_LF = 1\n",
    "        self.d_optimizer = tf.keras.optimizers.Adam(learning_rate=2e-4, beta_1=0.5, beta_2=0.999)\n",
    "        self.g_optimizer = tf.keras.optimizers.Adam(learning_rate=2e-4, beta_1=0.5, beta_2=0.999)\n",
    "\n",
    "        checkpoint_dir = './training_checkpoints'\n",
    "        self.checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "        self.checkpoint = tf.train.Checkpoint(generator_optimizer=self.g_optimizer,\n",
    "                                 discriminator_optimizer=self.d_optimizer,\n",
    "                                 generator=self.generator,\n",
    "                                 discriminator=self.discriminator)\n",
    "        # self.discriminator.summary()\n",
    "        # self.generator.summary()\n",
    "\n",
    "    # create generator model based on resnet50 and unet network\n",
    "    def build_generator_resnet50_unet(self, input_shape):\n",
    "        # print(inputs)\n",
    "        # print(\"pretained start\")\n",
    "        \"\"\" Pre-trained ResNet50 Model \"\"\"\n",
    "        resnet50 = tf.keras.applications.ResNet50(include_top=False, weights=\"imagenet\", input_tensor=input_shape)\n",
    "        # print(\"testing\")\n",
    "        \"\"\" Encoder using resnet50\"\"\"\n",
    "        # for layer in resnet50.layers:\n",
    "        #   print(layer.name)\n",
    "        s1 = resnet50.get_layer(\"input_1\").output           ## (128 x 128)\n",
    "        # print(s1)\n",
    "        s2 = resnet50.get_layer(\"conv1_relu\").output        ## (64 x 64)\n",
    "        s3 = resnet50.get_layer(\"conv2_block3_out\").output  ## (32 x 32)\n",
    "        s4 = resnet50.get_layer(\"conv3_block4_out\").output  ## (16 x 16)\n",
    "\n",
    "        \"\"\" Bridge \"\"\"\n",
    "        b1 = resnet50.get_layer(\"conv4_block6_out\").output  ## (32 x 32)\n",
    "\n",
    "        # print(\"test\")\n",
    "        # print(b1.get_weights())\n",
    "        \"\"\" Decoder unet\"\"\"\n",
    "        d1 = decoder_block(b1, s4, 128)                     ## (16 x 16)\n",
    "        d2 = decoder_block(d1, s3, 64)                     ## (32 x 32)\n",
    "        d3 = decoder_block(d2, s2, 32)                     ## (64 x 64)\n",
    "        d4 = decoder_block(d3, s1, 16)                      ## (128 x 128)\n",
    "\n",
    "        \"\"\" Output \"\"\"\n",
    "        final_model = tf.keras.layers.Conv2D(3, 1, padding=\"same\", activation=\"sigmoid\")(d4)\n",
    "\n",
    "        model = tf.keras.models.Model(inputs, outputs=[final_model, b1])\n",
    "\n",
    "        return model\n",
    "        # return outputs\n",
    "\n",
    "    # create discriminator model\n",
    "\n",
    "    def build_discriminator(self ,input_shape):\n",
    "      # Load the pre-trained model and freeze it.\n",
    "\n",
    "\n",
    "        x = tf.keras.layers.SeparableConvolution2D(32,kernel_size= (1, 1), strides=(2, 2), padding='same')(input_shape)\n",
    "        x = tf.keras.layers.LeakyReLU()(x)\n",
    "        x = tf.keras.layers.Dropout(0.3)(x)\n",
    "\n",
    "        x = tf.keras.layers.SeparableConvolution2D(64,kernel_size=(1, 1), strides=(2, 2), padding='same')(x)\n",
    "        x = tf.keras.layers.LeakyReLU()(x)\n",
    "        x = tf.keras.layers.Dropout(0.3)(x)\n",
    "\n",
    "        x = tf.keras.layers.Flatten()(x)\n",
    "        x = tf.keras.layers.Dense(1)(x)\n",
    "\n",
    "        model = tf.keras.models.Model(inputs, x)\n",
    "        return model\n",
    "        # return x\n",
    "\n",
    "    def compile(self, d_optimizer, g_optimizer):\n",
    "        super(ResUnetGAN, self).compile()\n",
    "        self.d_optimizer = d_optimizer\n",
    "        self.g_optimizer = g_optimizer\n",
    "\n",
    "  \n",
    "# Notice the use of `tf.function`\n",
    "# This annotation causes the function to be \"compiled\".\n",
    "    @tf.function\n",
    "    def train_step(self, images):\n",
    "\n",
    "\n",
    "        with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "            # tf.print(\"Images: \", images)\n",
    "            reconstructed_images, low_feature = self.generator(images, training=True)\n",
    "            real_output = self.discriminator(images, training=True)\n",
    "            # print(generated_images.shape)\n",
    "            fake_output = self.discriminator(reconstructed_images, training=True)\n",
    "            \n",
    "            # if tf.math.is_nan(real_output) is not None:\n",
    "            #     tf.print(tf.math.is_nan(real_output),\" real_output is NaN: \", real_output)\n",
    "            # else:\n",
    "            #     tf.print(real_output)\n",
    "            #\n",
    "            # if tf.math.is_nan(fake_output) is not None:\n",
    "            #     tf.print(tf.math.is_nan(fake_output),\" fake_output is NaN: \", fake_output)\n",
    "            # else:\n",
    "            #     tf.print(fake_output)\n",
    "            #\n",
    "            # if tf.math.is_nan(reconstructed_images) is not None:\n",
    "            #     tf.print(tf.math.is_nan(reconstructed_images),\" reconstructed_images is NaN: \",reconstructed_images)\n",
    "            # else:\n",
    "            #     tf.print(reconstructed_images)\n",
    "\n",
    "            # Loss 1: ADVERSARIAL loss\n",
    "            loss_adv = tf.reduce_mean(tf.math.log(real_output) + tf.math.log(1 - fake_output))\n",
    "            # Loss 2: RECONSTRUCTION loss\n",
    "            loss_rec = tf.math.reduce_sum(tf.math.abs(images - reconstructed_images), keepdims=True)\n",
    "            # Loss 3: SSIM loss\n",
    "            loss_ssim = 1 - tf.image.ssim(images,reconstructed_images, max_val=1.0)[0]\n",
    "            # Loss 4: FEATURE loss\n",
    "            loss_feat = tf.math.reduce_sum(tf.math.square(real_output - fake_output), keepdims=True)\n",
    "\n",
    "            gen_loss = tf.math.reduce_mean((loss_adv * self.ADV_REG_RATE_LF) + (loss_rec * self.REC_REG_RATE_LF) + (loss_ssim * self.SSIM_REG_RATE_LF) + (loss_feat * self.FEAT_REG_RATE_LF))\n",
    "            disc_loss = tf.math.reduce_mean((loss_adv * self.ADV_REG_RATE_LF) + (loss_feat * self.FEAT_REG_RATE_LF))\n",
    "\n",
    "        \n",
    "        gradients_of_generator = gen_tape.gradient(gen_loss, self.generator.trainable_variables)\n",
    "        gradients_of_discriminator = disc_tape.gradient(disc_loss, self.discriminator.trainable_variables)\n",
    "        \n",
    "        self.g_optimizer.apply_gradients(zip(gradients_of_generator, self.generator.trainable_variables))\n",
    "        self.d_optimizer.apply_gradients(zip(gradients_of_discriminator, self.discriminator.trainable_variables))\n",
    "\n",
    "        self.mean_loss_adv = tf.math.reduce_mean(loss_adv)\n",
    "        self.mean_loss_rec = tf.math.reduce_mean(loss_rec)\n",
    "        self.mean_loss_ssim = tf.math.reduce_mean(loss_ssim)\n",
    "        self.mean_loss_feat = tf.math.reduce_mean(loss_feat)\n",
    "\n",
    "        # tf.summary.scalar('loss_adv', self.mean_loss_adv)\n",
    "        # tf.summary.scalar('loss_rec', self.mean_loss_rec)\n",
    "        # tf.summary.scalar('loss_ssim', self.mean_loss_ssim)\n",
    "        # tf.summary.scalar('loss_feat', self.mean_loss_feat)\n",
    "        # tf.summary.scalar('gen_loss', gen_loss)\n",
    "        # tf.summary.scalar('disc_loss', disc_loss)\n",
    "\n",
    "\n",
    "        return {\n",
    "            \"gen_loss\": gen_loss,\n",
    "            \"disc_loss\": disc_loss,\n",
    "            \"loss_adv\": self.mean_loss_adv,\n",
    "            \"loss_rec\": self.mean_loss_rec,\n",
    "            \"loss_ssim\": self.mean_loss_ssim,\n",
    "            \"loss_feat\": self.mean_loss_feat\n",
    "        }\n",
    "\n",
    "    def saved_model(self, filepath, num_of_epoch):\n",
    "        self.generator.save(filepath + \"g_model\" + str(num_of_epoch) + \".h5\")\n",
    "        self.discriminator.save(filepath + \"d_model\" + str(num_of_epoch) + \".h5\")\n",
    "\n",
    "    def loaded_model(self, filepath):\n",
    "        self.generator.load_weights(filepath)\n",
    "        self.discriminator.load_weights(filepath)\n",
    "\n",
    "\n",
    "\n",
    "    def train(self, dataset, epochs):\n",
    "        for epoch in range(epochs):\n",
    "            start = time.time()\n",
    "            for image_batch in dataset:\n",
    "                # print(image_batch)\n",
    "                output = self.train_step(image_batch)\n",
    "                tf.print(output)\n",
    "\n",
    "            # Produce images for the GIF as you go\n",
    "            # display.clear_output(wait=True)\n",
    "            # generate_and_save_images(generator,\n",
    "            #                      epoch + 1,\n",
    "            #                      seed)\n",
    "            # Save the model every 15 epochs\n",
    "            if (epoch + 1) % 15 == 0:\n",
    "                self.checkpoint.save(file_prefix = self.checkpoint_prefix)\n",
    "                self.saved_model(\"mura_data/saved_model/\", num_epochs)\n",
    "                print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))"
   ],
   "execution_count": 27,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1KoSI9-4-tVt",
    "outputId": "bc609879-a7d8-427b-8390-9df4c65d51eb"
   },
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # run the function here\n",
    "    print(\"start\")\n",
    "    ## Hyperparameters\n",
    "    batch_size = 24\n",
    "    input_shape = (IMG_W, IMG_H, IMG_C)\n",
    "    # print(input_shape)\n",
    "\n",
    "    \"\"\" Input \"\"\"\n",
    "    inputs = tf.keras.layers.Input(input_shape, name=\"input_1\")\n",
    "\n",
    "    num_epochs = 600\n",
    "    train_images_path = glob(\"/Users/mrcaelumn/YZU/projects/mura_detector/mura_data/mura_data/train_data/*.bmp\")\n",
    "\n",
    "\n",
    "    # d_model = build_discriminator(inputs)\n",
    "    # g_model = build_generator_resnet50_unet(inputs)\n",
    "\n",
    "    resunetgan = ResUnetGAN(inputs, batch_size)\n",
    "\n",
    "\n",
    "    g_optimizer = tf.keras.optimizers.Adam(learning_rate=2e-4, beta_1=0.5, beta_2=0.999)\n",
    "    d_optimizer = tf.keras.optimizers.Adam(learning_rate=2e-4, beta_1=0.5, beta_2=0.999)\n",
    "    resunetgan.compile(d_optimizer, g_optimizer)\n",
    "\n",
    "    # print(train_images_path)\n",
    "    train_images_dataset = tf_dataset(train_images_path, batch_size)\n",
    "\n",
    "    # resunetgan.fit(train_images_dataset)\n",
    "\n",
    "    resunetgan.train(train_images_dataset, num_epochs)\n",
    "\n",
    "    # for epoch in range(num_epochs):\n",
    "    #     print(\"Epoch: \", epoch)\n",
    "    #     start = time.time()\n",
    "    #     for image_batch in train_images_dataset:\n",
    "    #     # print(image_batch.shape)\n",
    "    #\n",
    "    #         # print(\"Images_batch: \", image_batch)\n",
    "    #         resunetgan.fit(image_batch)\n",
    "    #         resunetgan.saved_model(\"mura_data/saved_model/\", num_epochs)\n",
    "\n",
    "    # resunetgan.summary()\n",
    "    # resunetgan.save_weights(\"saved_model/resunet_model\")\n",
    "\n"
   ],
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "{'disc_loss': -nan,\n",
      " 'gen_loss': -nan,\n",
      " 'loss_adv': -nan,\n",
      " 'loss_feat': 0.00990263373,\n",
      " 'loss_rec': 813757.375,\n",
      " 'loss_ssim': 1.03180218}\n",
      "{'disc_loss': -4.09455109,\n",
      " 'gen_loss': 40538140,\n",
      " 'loss_adv': -4.10939884,\n",
      " 'loss_feat': 0.0148478569,\n",
      " 'loss_rec': 810761.875,\n",
      " 'loss_ssim': 1.02948236}\n",
      "{'disc_loss': -nan,\n",
      " 'gen_loss': -nan,\n",
      " 'loss_adv': -nan,\n",
      " 'loss_feat': 0.0152015425,\n",
      " 'loss_rec': 806140,\n",
      " 'loss_ssim': 1.03032172}\n",
      "{'disc_loss': -nan,\n",
      " 'gen_loss': -nan,\n",
      " 'loss_adv': -nan,\n",
      " 'loss_feat': 0.0528374687,\n",
      " 'loss_rec': 795360,\n",
      " 'loss_ssim': 1.02791846}\n",
      "{'disc_loss': -4.24771595,\n",
      " 'gen_loss': 39743768,\n",
      " 'loss_adv': -4.25684357,\n",
      " 'loss_feat': 0.00912741106,\n",
      " 'loss_rec': 794874.375,\n",
      " 'loss_ssim': 1.02634335}\n",
      "{'disc_loss': -3.73770523,\n",
      " 'gen_loss': 39637256,\n",
      " 'loss_adv': -3.74607348,\n",
      " 'loss_feat': 0.00836825743,\n",
      " 'loss_rec': 792744.188,\n",
      " 'loss_ssim': 1.03680587}\n",
      "{'disc_loss': -3.82523084,\n",
      " 'gen_loss': 10038176,\n",
      " 'loss_adv': -3.82780838,\n",
      " 'loss_feat': 0.00257750927,\n",
      " 'loss_rec': 200762.562,\n",
      " 'loss_ssim': 1.03361368}\n",
      "{'disc_loss': -3.88901162,\n",
      " 'gen_loss': 39594340,\n",
      " 'loss_adv': -3.90025806,\n",
      " 'loss_feat': 0.0112464316,\n",
      " 'loss_rec': 791885.875,\n",
      " 'loss_ssim': 1.03230882}\n",
      "{'disc_loss': -4.29124165,\n",
      " 'gen_loss': 38852340,\n",
      " 'loss_adv': -4.30773354,\n",
      " 'loss_feat': 0.0164919868,\n",
      " 'loss_rec': 777045.812,\n",
      " 'loss_ssim': 1.03275502}\n",
      "{'disc_loss': -nan,\n",
      " 'gen_loss': -nan,\n",
      " 'loss_adv': -nan,\n",
      " 'loss_feat': 0.0775010511,\n",
      " 'loss_rec': 777286.938,\n",
      " 'loss_ssim': 1.03759253}\n",
      "{'disc_loss': -nan,\n",
      " 'gen_loss': -nan,\n",
      " 'loss_adv': -nan,\n",
      " 'loss_feat': 0.0413906425,\n",
      " 'loss_rec': 780120.188,\n",
      " 'loss_ssim': 1.0473671}\n",
      "{'disc_loss': -4.44673586,\n",
      " 'gen_loss': 38623356,\n",
      " 'loss_adv': -4.45848227,\n",
      " 'loss_feat': 0.0117463302,\n",
      " 'loss_rec': 772466.125,\n",
      " 'loss_ssim': 1.04050183}\n",
      "{'disc_loss': -4.42104626,\n",
      " 'gen_loss': 38709116,\n",
      " 'loss_adv': -4.42828655,\n",
      " 'loss_feat': 0.0072403783,\n",
      " 'loss_rec': 774181.375,\n",
      " 'loss_ssim': 1.04954481}\n",
      "{'disc_loss': -4.90776777,\n",
      " 'gen_loss': 9.53022e+06,\n",
      " 'loss_adv': -4.91062212,\n",
      " 'loss_feat': 0.00285440194,\n",
      " 'loss_rec': 190603.469,\n",
      " 'loss_ssim': 1.04234469}\n",
      "{'disc_loss': -nan,\n",
      " 'gen_loss': -nan,\n",
      " 'loss_adv': -nan,\n",
      " 'loss_feat': 0.024295086,\n",
      " 'loss_rec': 760491.688,\n",
      " 'loss_ssim': 1.04050422}\n",
      "{'disc_loss': -nan,\n",
      " 'gen_loss': -nan,\n",
      " 'loss_adv': -nan,\n",
      " 'loss_feat': 0.135207146,\n",
      " 'loss_rec': 754985.312,\n",
      " 'loss_ssim': 1.04287899}\n",
      "{'disc_loss': -nan,\n",
      " 'gen_loss': -nan,\n",
      " 'loss_adv': -nan,\n",
      " 'loss_feat': 0.292348504,\n",
      " 'loss_rec': 750242.25,\n",
      " 'loss_ssim': 1.04766309}\n",
      "{'disc_loss': -nan,\n",
      " 'gen_loss': -nan,\n",
      " 'loss_adv': -nan,\n",
      " 'loss_feat': 0.284038842,\n",
      " 'loss_rec': 753913.625,\n",
      " 'loss_ssim': 1.05273604}\n",
      "{'disc_loss': -nan,\n",
      " 'gen_loss': -nan,\n",
      " 'loss_adv': -nan,\n",
      " 'loss_feat': 0.292180836,\n",
      " 'loss_rec': 750098.5,\n",
      " 'loss_ssim': 1.0533886}\n",
      "{'disc_loss': -nan,\n",
      " 'gen_loss': -nan,\n",
      " 'loss_adv': -nan,\n",
      " 'loss_feat': 0.247714162,\n",
      " 'loss_rec': 748977.875,\n",
      " 'loss_ssim': 1.04941964}\n",
      "{'disc_loss': -nan,\n",
      " 'gen_loss': -nan,\n",
      " 'loss_adv': -nan,\n",
      " 'loss_feat': 0.0431105,\n",
      " 'loss_rec': 185095.25,\n",
      " 'loss_ssim': 1.04801047}\n",
      "{'disc_loss': -nan,\n",
      " 'gen_loss': -nan,\n",
      " 'loss_adv': -nan,\n",
      " 'loss_feat': 0.166665673,\n",
      " 'loss_rec': 738570.562,\n",
      " 'loss_ssim': 1.04886866}\n",
      "{'disc_loss': -nan,\n",
      " 'gen_loss': -nan,\n",
      " 'loss_adv': -nan,\n",
      " 'loss_feat': 0.159756109,\n",
      " 'loss_rec': 732846.625,\n",
      " 'loss_ssim': 1.05880666}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-28-1cafa1200310>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     29\u001B[0m     \u001B[0;31m# resunetgan.fit(train_images_dataset)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     30\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 31\u001B[0;31m     \u001B[0mresunetgan\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtrain\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtrain_images_dataset\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnum_epochs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     32\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     33\u001B[0m     \u001B[0;31m# for epoch in range(num_epochs):\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-27-0b8d16780ecc>\u001B[0m in \u001B[0;36mtrain\u001B[0;34m(self, dataset, epochs)\u001B[0m\n\u001B[1;32m    166\u001B[0m             \u001B[0;32mfor\u001B[0m \u001B[0mimage_batch\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mdataset\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    167\u001B[0m                 \u001B[0;31m# print(image_batch)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 168\u001B[0;31m                 \u001B[0moutput\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtrain_step\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mimage_batch\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    169\u001B[0m                 \u001B[0mtf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0moutput\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    170\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/YZU/.jupyter_env/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    887\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    888\u001B[0m       \u001B[0;32mwith\u001B[0m \u001B[0mOptionalXlaContext\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_jit_compile\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 889\u001B[0;31m         \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    890\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    891\u001B[0m       \u001B[0mnew_tracing_count\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mexperimental_get_tracing_count\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/YZU/.jupyter_env/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001B[0m in \u001B[0;36m_call\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    915\u001B[0m       \u001B[0;31m# In this case we have created variables on the first call, so we run the\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    916\u001B[0m       \u001B[0;31m# defunned version which is guaranteed to never create variables.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 917\u001B[0;31m       \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_stateless_fn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[0;34m)\u001B[0m  \u001B[0;31m# pylint: disable=not-callable\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    918\u001B[0m     \u001B[0;32melif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_stateful_fn\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    919\u001B[0m       \u001B[0;31m# Release the lock early so that multiple threads can perform the call\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/YZU/.jupyter_env/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   3021\u001B[0m       (graph_function,\n\u001B[1;32m   3022\u001B[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001B[0;32m-> 3023\u001B[0;31m     return graph_function._call_flat(\n\u001B[0m\u001B[1;32m   3024\u001B[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001B[1;32m   3025\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/YZU/.jupyter_env/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001B[0m in \u001B[0;36m_call_flat\u001B[0;34m(self, args, captured_inputs, cancellation_manager)\u001B[0m\n\u001B[1;32m   1958\u001B[0m         and executing_eagerly):\n\u001B[1;32m   1959\u001B[0m       \u001B[0;31m# No tape is watching; skip to running the function.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1960\u001B[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001B[0m\u001B[1;32m   1961\u001B[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001B[1;32m   1962\u001B[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001B[0;32m~/YZU/.jupyter_env/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001B[0m in \u001B[0;36mcall\u001B[0;34m(self, ctx, args, cancellation_manager)\u001B[0m\n\u001B[1;32m    589\u001B[0m       \u001B[0;32mwith\u001B[0m \u001B[0m_InterpolateFunctionError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    590\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mcancellation_manager\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 591\u001B[0;31m           outputs = execute.execute(\n\u001B[0m\u001B[1;32m    592\u001B[0m               \u001B[0mstr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msignature\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    593\u001B[0m               \u001B[0mnum_outputs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_num_outputs\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/YZU/.jupyter_env/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001B[0m in \u001B[0;36mquick_execute\u001B[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[1;32m     57\u001B[0m   \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     58\u001B[0m     \u001B[0mctx\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mensure_initialized\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 59\u001B[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001B[0m\u001B[1;32m     60\u001B[0m                                         inputs, attrs, num_outputs)\n\u001B[1;32m     61\u001B[0m   \u001B[0;32mexcept\u001B[0m \u001B[0mcore\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_NotOkStatusException\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "F-qJN0EEQwb6"
   },
   "source": [
    "# load an image\n",
    "def load_image_test(filename, size=(128,128)):\n",
    "\t# load image with the preferred size\n",
    "\tpixels = tf.keras.preprocessing.image.load_img(filename, target_size=size)\n",
    "\t# convert to numpy array\n",
    "\tpixels = tf.keras.preprocessing.image.img_to_array(pixels)\n",
    "\t# scale from [0,255] to [-1,1]\n",
    "\tpixels = (pixels - 127.5) / 127.5\n",
    "\t# reshape to 1 sample\n",
    "\tpixels = np.expand_dims(pixels, 0)\n",
    "\treturn pixels"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "-8pFOeDNLuR7",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "outputId": "9bfb095a-efef-4a78-e03a-86744b6f168a"
   },
   "source": [
    "# test_images_dataset = tf_dataset(test_images_path, batch_size)\n",
    "# normal_images = glob('mura_data/mura_data/test_data/normal_*.bmp')\n",
    "# defect_images = glob('mura_data/mura_data/test_data/defect_*.bmp')\n",
    "# len_nor_data = len(normal_images)\n",
    "# len_def_data = len(defect_images)\n",
    "# print(len_nor_data)\n",
    "# print(len_def_data)\n",
    "# threshold = 0.6\n",
    "# defect_preds = []\n",
    "# for image in defect_images:\n",
    "#   # print(image)\n",
    "#   if \"DS_Store\" not in image:\n",
    "#     src_image = load_image_test(image)\n",
    "#\n",
    "#     test = d_model.predict(src_image)\n",
    "#     test = (test + 1) / 2.0\n",
    "#     defect_preds = np.append(defect_preds,test)\n",
    "#\n",
    "#     # preds = (preds - preds.min())/(preds.max()-preds.min())\n",
    "#     # print(test)\n",
    "#\n",
    "#\n",
    "#\n",
    "# normal_preds = []\n",
    "# for image in normal_images:\n",
    "#   # print(image)\n",
    "#   if \"DS_Store\" not in image:\n",
    "#     src_image = load_image_test(image)\n",
    "#\n",
    "#     test = d_model.predict(src_image)\n",
    "#     test = (test + 1) / 2.0\n",
    "#     normal_preds = np.append(normal_preds,test)\n",
    "#\n",
    "#     # preds = (preds - preds.min())/(preds.max()-preds.min())\n",
    "#     # print(test)\n",
    "#\n",
    "#\n",
    "# print(defect_preds)\n",
    "# print(np.mean(defect_preds))\n",
    "# true_def_pred = len(np.where(defect_preds > threshold)[0])\n",
    "# print(true_def_pred)\n",
    "#\n",
    "#\n",
    "# print(normal_preds)\n",
    "# print(np.mean(normal_preds))\n",
    "# true_nor_pred = len(np.where(normal_preds < threshold)[0])\n",
    "# print(true_nor_pred)\n",
    "#\n",
    "# total_acc = (true_def_pred + true_nor_pred) / (len_nor_data + len_def_data) * 100\n",
    "# print(\"total_accuracy: \", total_acc)\n",
    "\n"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "51\n",
      "50\n",
      "[0.64748341 0.64582115 0.64495695 0.63706183 0.64389598 0.64372158\n",
      " 0.64029634 0.64423901 0.63870716 0.64056474 0.63585079 0.63704026\n",
      " 0.6411283  0.64476216 0.63866848 0.63880849 0.63715732 0.63976002\n",
      " 0.64145702 0.64556265 0.64365792 0.6378026  0.64362186 0.63863498\n",
      " 0.64006096 0.64166403 0.64609551 0.63979173 0.64554846 0.63616109\n",
      " 0.64451241 0.64017868 0.6469053  0.63884485 0.63761288 0.64289093\n",
      " 0.64132708 0.64631164 0.64095742 0.63797343 0.64088923 0.63647813\n",
      " 0.65117645 0.63967681 0.64133358 0.63783252 0.64289385 0.64198399\n",
      " 0.63981831 0.63435316]\n",
      "0.6412786686420441\n",
      "50\n",
      "[0.63939631 0.64166212 0.63711405 0.63674265 0.63656467 0.63669407\n",
      " 0.63940752 0.63682628 0.63999265 0.63952291 0.63734055 0.64020377\n",
      " 0.63860971 0.640733   0.64046967 0.63901877 0.63815737 0.63886672\n",
      " 0.6363433  0.63823372 0.63949871 0.63427675 0.63712913 0.64116955\n",
      " 0.63772613 0.63943613 0.63968712 0.6397562  0.63884401 0.64015615\n",
      " 0.63704967 0.64029896 0.63756126 0.63938802 0.63810068 0.63947988\n",
      " 0.63981718 0.6367234  0.63923091 0.63839173 0.63806874 0.63837016\n",
      " 0.64042914 0.64004749 0.6408875  0.63947093 0.63853627 0.63996935\n",
      " 0.63839281 0.63756096]\n",
      "0.6387470948696137\n",
      "0\n",
      "total_accuracy:  49.504950495049506\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "x3EaS4Uz6ZDV"
   },
   "source": [
    ""
   ],
   "execution_count": null,
   "outputs": []
  }
 ]
}